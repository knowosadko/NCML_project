{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "12eac9e0",
        "outputId": "4b867fd7-359d-4e5e-e53e-5da6f4ff6b85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting gymnasium\n",
            "  Downloading gymnasium-0.28.1-py3-none-any.whl (925 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m925.5/925.5 kB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (1.22.4)\n",
            "Collecting jax-jumpy>=1.0.0 (from gymnasium)\n",
            "  Downloading jax_jumpy-1.0.0-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (4.5.0)\n",
            "Collecting farama-notifications>=0.0.1 (from gymnasium)\n",
            "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
            "Installing collected packages: farama-notifications, jax-jumpy, gymnasium\n",
            "Successfully installed farama-notifications-0.0.4 gymnasium-0.28.1 jax-jumpy-1.0.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gymnasium[accept-rom-license,atari] in /usr/local/lib/python3.10/dist-packages (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[accept-rom-license,atari]) (1.22.4)\n",
            "Requirement already satisfied: jax-jumpy>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[accept-rom-license,atari]) (1.0.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[accept-rom-license,atari]) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[accept-rom-license,atari]) (4.5.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium[accept-rom-license,atari]) (0.0.4)\n",
            "Collecting autorom[accept-rom-license]~=0.4.2 (from gymnasium[accept-rom-license,atari])\n",
            "  Downloading AutoROM-0.4.2-py3-none-any.whl (16 kB)\n",
            "Collecting shimmy[atari]<1.0,>=0.1.0 (from gymnasium[accept-rom-license,atari])\n",
            "  Downloading Shimmy-0.2.1-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.4.2->gymnasium[accept-rom-license,atari]) (8.1.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.4.2->gymnasium[accept-rom-license,atari]) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.4.2->gymnasium[accept-rom-license,atari]) (4.65.0)\n",
            "Collecting AutoROM.accept-rom-license (from autorom[accept-rom-license]~=0.4.2->gymnasium[accept-rom-license,atari])\n",
            "  Downloading AutoROM.accept-rom-license-0.6.1.tar.gz (434 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.7/434.7 kB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ale-py~=0.8.1 (from shimmy[atari]<1.0,>=0.1.0->gymnasium[accept-rom-license,atari])\n",
            "  Downloading ale_py-0.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m86.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from ale-py~=0.8.1->shimmy[atari]<1.0,>=0.1.0->gymnasium[accept-rom-license,atari]) (5.12.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gymnasium[accept-rom-license,atari]) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gymnasium[accept-rom-license,atari]) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gymnasium[accept-rom-license,atari]) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gymnasium[accept-rom-license,atari]) (3.4)\n",
            "Building wheels for collected packages: AutoROM.accept-rom-license\n",
            "  Building wheel for AutoROM.accept-rom-license (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for AutoROM.accept-rom-license: filename=AutoROM.accept_rom_license-0.6.1-py3-none-any.whl size=446660 sha256=888f51dab66cd8cc3ba0c669627a8b88b0811eaf83c09646f26e0be39db70f40\n",
            "  Stored in directory: /root/.cache/pip/wheels/6b/1b/ef/a43ff1a2f1736d5711faa1ba4c1f61be1131b8899e6a057811\n",
            "Successfully built AutoROM.accept-rom-license\n",
            "Installing collected packages: ale-py, AutoROM.accept-rom-license, autorom, shimmy\n",
            "Successfully installed AutoROM.accept-rom-license-0.6.1 ale-py-0.8.1 autorom-0.4.2 shimmy-0.2.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.15.2+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.27.1)\n",
            "Requirement already satisfied: torch==2.0.1 in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.0.1+cu118)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (8.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->torchvision) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->torchvision) (16.0.5)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.1->torchvision) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.1->torchvision) (1.3.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.22.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "! pip install gymnasium\n",
        "! pip install \"gymnasium[atari, accept-rom-license]\"\n",
        "! pip install torch\n",
        "! pip install torchvision\n",
        "! pip install numpy\n",
        "! pip install matplotlib"
      ],
      "id": "12eac9e0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Sj2qUKs-nJi",
        "outputId": "84c61906-63bd-418c-9f33-e31539d56943"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "2Sj2qUKs-nJi"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7a753e25",
        "outputId": "84794cd8-c302-4dcb-9033-f5aff849d0b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘drive/MyDrive/logs_Pacman’: File exists\n",
            "mkdir: cannot create directory ‘drive/MyDrive/videos_Pacman’: File exists\n"
          ]
        }
      ],
      "source": [
        "! mkdir drive/MyDrive/logs_Pacman\n",
        "! mkdir drive/MyDrive/videos_Pacman"
      ],
      "id": "7a753e25"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "343f5217"
      },
      "outputs": [],
      "source": [
        "#import ale_py\n",
        "#import shimmy\n",
        "import gymnasium as gym\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, random_split, Dataset\n",
        "from torch.nn import functional as F\n",
        "from torchvision import datasets, transforms\n",
        "import torchvision.transforms.functional as TF\n",
        "import random\n",
        "import copy\n",
        "import time\n",
        "import pickle\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import json\n"
      ],
      "id": "343f5217"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7a15bb46"
      },
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()   \n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=8, stride=4),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=4, stride=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        \n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(in_features=64*7*7 , out_features=512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_features=512, out_features=5)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        conv_out = self.conv(x)\n",
        "        x = torch.flatten(conv_out, start_dim=1)\n",
        "        return self.fc(x)\n",
        "        "
      ],
      "id": "7a15bb46"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c5dce59e",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "class Memory():\n",
        "    \n",
        "    def __init__(self,size):\n",
        "        self.size = size\n",
        "        self.experiences = []\n",
        "    \n",
        "    def sample(self,batch_size):\n",
        "        return random.choices(self.experiences, k=batch_size)\n",
        "        \n",
        "    def add(self, experience):\n",
        "        self.experiences.append(experience)\n",
        "        if len(self.experiences) > self.size:\n",
        "            self.experiences.pop(0)\n",
        "                    \n",
        "    def __len__(self):\n",
        "        return len(self.experiences)"
      ],
      "id": "c5dce59e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f008d8b8"
      },
      "outputs": [],
      "source": [
        "class DQN_agent:\n",
        "\n",
        "\n",
        "    def __init__(self, lr=0.0001 ,gamma=0.99, epsilon_params=(0.9,0.05,1000)):\n",
        "        # Get cpu, gpu or mps device for training.\n",
        "        self.device = (\n",
        "            \"cuda\"\n",
        "            if torch.cuda.is_available()\n",
        "            else \"mps\"\n",
        "            if torch.backends.mps.is_available()\n",
        "            else \"cpu\"\n",
        "        )\n",
        "        print(f\"Using {self.device} device\")\n",
        "        self.pred_NN = CNN().to(self.device)\n",
        "        self.target_NN = copy.deepcopy(self.pred_NN)\n",
        "        self.target_NN.eval()\n",
        "        self.gamma = gamma\n",
        "        self.epsilon_start = epsilon_params[0]\n",
        "        self.epsilon_end = epsilon_params[1]\n",
        "        self.epsilon_decay = epsilon_params[2]\n",
        "        self.optimizer = torch.optim.RMSprop(self.pred_NN.parameters(), lr=lr)\n",
        "        self.steps_done = 0\n",
        "        \n",
        "    def predict(self, x):\n",
        "        self.steps_done += 1\n",
        "        return self.pred_NN.forward(x)\n",
        "    \n",
        "    def action(self, pred):\n",
        "        eps = self.epsilon_end + (self.epsilon_start - self.epsilon_end) * math.exp(-1. * self.steps_done / self.epsilon_decay)\n",
        "        return (\n",
        "            random.randint(0, pred.size(dim=0) - 1)\n",
        "            if random.random() < eps\n",
        "            else torch.argmax(pred).item()\n",
        "        )\n",
        "    \n",
        "    def train(self, experience_batch):\n",
        "        loss_fn = nn.SmoothL1Loss()\n",
        "        epoch_loss = 0\n",
        "        states = torch.stack([experience_batch[i][0].squeeze(0) for i in range(len(experience_batch))]).to(self.device)\n",
        "        actions = torch.tensor([experience_batch[i][1] for i in range(len(experience_batch))])\n",
        "        rewards = torch.tensor([experience_batch[i][2] for i in range(len(experience_batch))]).to(self.device)#torch.tensor(experience_batch[:][2])\n",
        "        next_states = torch.stack([experience_batch[i][3].squeeze(0)  for i in range(len(experience_batch))]).to(self.device)\n",
        "        terminated = torch.tensor([not experience_batch[i][4] for i in range(len(experience_batch))]).to(self.device)\n",
        "        y = self.estimated_value( rewards, next_states, terminated)\n",
        "        self.optimizer.zero_grad()\n",
        "        pred = self.pred_NN(states)\n",
        "        indicies = torch.LongTensor(actions)\n",
        "        indicies =indicies.unsqueeze(dim=0).T\n",
        "        pred = pred.gather(1,indicies.to(self.device))\n",
        "        loss = loss_fn(y, pred)\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "        return epoch_loss\n",
        "        \n",
        "    def copy(self):\n",
        "        self.target_NN.load_state_dict(self.pred_NN.state_dict())  \n",
        "        \n",
        "    def estimated_value(self, reward, next_state, done):\n",
        "        with torch.no_grad():# vectorize it\n",
        "                target_pred = self.target_NN.forward(next_state.to(self.device))\n",
        "                max_pred = torch.max(target_pred,1)[0].unsqueeze(1)\n",
        "                done = done.unsqueeze(1)\n",
        "                target = reward.unsqueeze(1) + self.gamma * torch.mul(max_pred,done)\n",
        "        return target\n",
        "        "
      ],
      "id": "f008d8b8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0b4d1cca"
      },
      "outputs": [],
      "source": [
        "def adjust_to_torch(t):\n",
        "    t = t.unsqueeze(dim=0)\n",
        "    return torch.movedim(t, 3, 1)"
      ],
      "id": "0b4d1cca"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "b7d4bd0a",
        "outputId": "5efda828-61e8-492e-bc0d-8eb4b8feaedf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gymnasium/wrappers/record_video.py:87: UserWarning: \u001b[33mWARN: Overwriting existing videos at /content/drive/MyDrive/videos_Pacman/videos folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
            "  logger.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cuda device\n",
            "Episode: 1 Reward: 1.0 loss: 0.0 last rewards: 1.0\n",
            "Episode: 2 Reward: 0.0 loss: 0.0 last rewards: 0.5\n",
            "Episode: 3 Reward: 8.0 loss: 0.0018618460297234688 last rewards: 3.0\n",
            "Episode: 4 Reward: 3.0 loss: 0.003029352386649018 last rewards: 3.0\n",
            "Episode: 5 Reward: 18.0 loss: 0.00529767489889909 last rewards: 6.0\n",
            "Episode: 6 Reward: 16.0 loss: 0.004883991837825881 last rewards: 7.666666666666667\n",
            "Episode: 7 Reward: 4.0 loss: 0.005677830882531352 last rewards: 7.142857142857143\n",
            "Episode: 8 Reward: 12.0 loss: 0.004616890028069951 last rewards: 7.75\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-f53d14c52823>\u001b[0m in \u001b[0;36m<cell line: 32>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0mexperiences_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0mepisode_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiences_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m             \u001b[0mtraining_session\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0msteps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-04674b0968eb>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, experience_batch)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexperience_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperience_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mrewards\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexperience_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperience_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#torch.tensor(experience_batch[:][2])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mnext_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexperience_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperience_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0mterminated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mexperience_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperience_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimated_value\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterminated\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#initialize environment\n",
        "env = gym.make(\"ALE/Pacman-v5\", render_mode=\"rgb_array\")\n",
        "env.seed(543)\n",
        "env = gym.wrappers.AtariPreprocessing(env, screen_size=84, grayscale_obs=False, frame_skip=1, noop_max=40)\n",
        "env = gym.wrappers.RecordVideo(env, './drive/MyDrive/videos_Pacman/videos', episode_trigger = lambda x: (x+1) % 100 == 0)# PATH\n",
        "# env = NoopResetEnv(env, noop_max=30)\n",
        "replay_buffer = Memory(10000)\n",
        "torch.manual_seed(53407)\n",
        "actions = range(env.action_space.n)\n",
        "device = (\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
        "#hyperparams\n",
        "max_steps = 9999\n",
        "training_freq = 1\n",
        "copying_freq = 20\n",
        "batch_size = 64\n",
        "\n",
        "#initialize agent\n",
        "agent = DQN_agent(lr=2e-4,gamma=0.99)\n",
        "\n",
        "training_session = 0\n",
        "max_episode = 2000\n",
        "\n",
        "#loops until max_time is reached\n",
        "memory = Memory(10000)\n",
        "\n",
        "total_steps = 0\n",
        "last_rewards = []\n",
        "\n",
        "episodes = []\n",
        "losses = []\n",
        "logger = {\"episodes\":[],\"losses\":[]}\n",
        "for episode  in range(1,max_episode):\n",
        "    #get first states\n",
        "    state = env.reset()\n",
        "    state = state[0]/255\n",
        "    state = torch.Tensor(state)\n",
        "    state = adjust_to_torch(state)\n",
        "    #loops until experience_capacity is reached\n",
        "    episode_reward = 0 \n",
        "    episode_loss = 0\n",
        "    steps = 0\n",
        "    for i in range(1, max_steps):\n",
        "        #predict q-values and choose action\n",
        "        with torch.no_grad():\n",
        "            pred = agent.predict(state.to(device))\n",
        "        action = agent.action(pred)\n",
        "        #get next states\n",
        "        next_state, reward, terminated, truncated, info = env.step(action)\n",
        "        episode_reward += reward\n",
        "        if i == max_steps - 1:\n",
        "            print(\"Max steps reached.\")\n",
        "        next_state = adjust_to_torch(torch.tensor(next_state)/255)\n",
        "        experience = [state, action, reward, next_state, terminated] \n",
        "        memory.add(experience)\n",
        "        if terminated or truncated:\n",
        "            break\n",
        "        state = next_state      \n",
        "        if len(memory) > 1000:\n",
        "            experiences_train = memory.sample(batch_size)\n",
        "            episode_loss += agent.train(experiences_train)\n",
        "            training_session += 1\n",
        "            steps += 1\n",
        "        total_steps += 1\n",
        "        steps = i\n",
        "    #if episode % 100 == 0:\n",
        "    if episode % copying_freq == 0:\n",
        "        agent.copy()\n",
        "    if episode % 2 == 0:\n",
        "        logger[\"episodes\"].append(episodes)\n",
        "        logger[\"losses\"].append(losses)\n",
        "        episodes = []\n",
        "        losses = []\n",
        "    if episode % 100 == 0:\n",
        "        with open('./drive/MyDrive/logs_Pacman/logger_ddqn.json', 'w') as fp:# PATH\n",
        "            json.dump(logger, fp)\n",
        "    if episode % 250 == 0:\n",
        "      torch.save(agent.pred_NN.state_dict(), \"./drive/MyDrive/logs_Pacman/pred.pt\")\n",
        "      torch.save(agent.target_NN.state_dict(), \"./drive/MyDrive/logs_Pacman/target.pt\")\n",
        "    last_rewards.append(episode_reward)\n",
        "    episodes.append(episode_reward)\n",
        "    losses.append(episode_loss/steps)\n",
        "    if steps > 0:\n",
        "      print(f\"Episode: {episode} Reward: {episode_reward} loss: {episode_loss/steps} last rewards: {sum(last_rewards)/len(last_rewards)}\")\n",
        "    \n"
      ],
      "id": "b7d4bd0a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5a7746d9"
      },
      "outputs": [],
      "source": [],
      "id": "5a7746d9"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}