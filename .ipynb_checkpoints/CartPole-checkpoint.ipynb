{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a147f0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import ale_py\n",
    "#import shimmy\n",
    "import gymnasium as gym\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, random_split, Dataset\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "#import os\n",
    "import random\n",
    "import copy\n",
    "import time\n",
    "import pickle\n",
    "#import torcheck\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "474f722f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CNN(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()   \n",
    "        \n",
    "        self.stack = torch.nn.Sequential(\n",
    "            nn.Linear(4, 8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(8, 8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(8, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.stack(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fc12362",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN_agent:\n",
    "\n",
    "    def __init__(self):\n",
    "        # Get cpu, gpu or mps device for training.\n",
    "        self.device = (\n",
    "            \"cuda\"\n",
    "            if torch.cuda.is_available()\n",
    "            else \"mps\"\n",
    "            if torch.backends.mps.is_available()\n",
    "            else \"cpu\"\n",
    "        )\n",
    "        print(f\"Using {self.device} device\")\n",
    "        self.pred_NN = CNN().to(self.device)\n",
    "        self.target_NN = copy.deepcopy(self.pred_NN)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        pred = self.pred_NN.forward(x)\n",
    "        return pred\n",
    "    \n",
    "    def action(self, pred):\n",
    "        if random.random() < epsilon:\n",
    "            action = random.randint(0, pred.size(dim=0) - 1)\n",
    "        else: \n",
    "            action = torch.argmax(pred).item()\n",
    "        return action\n",
    "    \n",
    "    def train(self, experiences):\n",
    "      \n",
    "        data_set = ExperiencesDataset(experiences, self)\n",
    "        data_loader = DataLoader(data_set, batch_size=samples_per_batch, shuffle=True)\n",
    "        optimizer = torch.optim.SGD(self.pred_NN.parameters(), lr=0.1)\n",
    "        loss_fn = nn.MSELoss()\n",
    "        epoch_loss = 0\n",
    "        \n",
    "        self.pred_NN.train()\n",
    "\n",
    "        #torcheck.register(optimizer)\n",
    "        #torcheck.add_module_changing_check(self.pred_NN, module_name=\"my_model\")\n",
    "        \n",
    "        for batch, (state, y) in enumerate(data_loader):\n",
    "            \n",
    "            pred = self.pred_NN(state)\n",
    "            loss = loss_fn(pred, y)\n",
    "            \n",
    "            loss.backward(retain_graph=True)\n",
    "            #print('****** Gradients ******')\n",
    "            #for p in self.pred_NN.parameters():\n",
    "                #print(p.grad.norm())\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            if batch == (len(data_loader) - 1):\n",
    "                self.pred_NN.train(mode=False)\n",
    "                return epoch_loss\n",
    "        \n",
    "    def copy(self):\n",
    "        self.target_NN = copy.deepcopy(self.pred_NN)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ff3d2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExperiencesDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, experiences, agent):\n",
    "    \n",
    "        self.states = []\n",
    "        self.labels = []\n",
    "        \n",
    "        for n, experience in enumerate(experiences):\n",
    "            #print('**************  CREATE LABEL  ********************\\n')\n",
    "            state, action, reward, next_state = experience\n",
    "            \n",
    "            #print('STATE\\n')\n",
    "            #print(state, '\\n')\n",
    "            #img = state[0].permute(1, 2, 0).numpy()\n",
    "            #plt.imshow(img)\n",
    "            #plt.show()\n",
    "            \n",
    "            #print('NEXT STATE\\n')\n",
    "            #print(next_state, '\\n')\n",
    "            #img = next_state[0].permute(1, 2, 0).numpy()\n",
    "            #plt.imshow(img)\n",
    "            #plt.show()\n",
    "\n",
    "            #print('reward: ', reward, '\\n')\n",
    "            #print('action: ', action, '\\n')\n",
    "            \n",
    "            pred = agent.predict(state)\n",
    "            #label = pred.detach().clone().squeeze()\n",
    "            label = pred.detach().clone()\n",
    "            \n",
    "            #print('pred: ', label, '\\n')\n",
    "            \n",
    "            target_pred = agent.target_NN.forward(next_state)\n",
    "            #target_pred = target_pred.squeeze()\n",
    "            target = reward + gamma * max(target_pred)\n",
    "            \n",
    "            \n",
    "            label[action] = target\n",
    "            #print('label: ', label, '\\n')\n",
    "            \n",
    "            self.labels.append(label) \n",
    "            \n",
    "            #state = state.squeeze()\n",
    "            self.states.append(state)\n",
    "            #print('********************  END  ***********************\\n')\n",
    "    def __len__(self):\n",
    "        return len(self.states)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.states[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9751d961",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "action:  0\n",
      "Plot filters in first layer\n",
      "\n",
      "*********  Elapsed time: 56.992533683776855 seconds  *************\n",
      "\n",
      "------Epsilon decays after 56.99353289604187 seconds since last decay-----\n",
      "\n",
      "old epsilon: 0.5 \n",
      "\n",
      "new epsilon: 0.5\n",
      "\n",
      "Average states alive:  17.266471119133573 \n",
      "\n",
      "*********  Elapsed time: 113.37213683128357 seconds  *************\n",
      "\n",
      "------Epsilon decays after 56.3786039352417 seconds since last decay-----\n",
      "\n",
      "old epsilon: 0.5 \n",
      "\n",
      "new epsilon: 0.5\n",
      "\n",
      "Average states alive:  26.453015427769987 \n",
      "\n",
      "*********  Elapsed time: 169.6320264339447 seconds  *************\n",
      "\n",
      "------Epsilon decays after 56.26089644432068 seconds since last decay-----\n",
      "\n",
      "old epsilon: 0.5 \n",
      "\n",
      "new epsilon: 0.5\n",
      "\n",
      "Average states alive:  35.642600457366875 \n",
      "\n",
      "*********  Elapsed time: 226.20787620544434 seconds  *************\n",
      "\n",
      "------Epsilon decays after 56.57484292984009 seconds since last decay-----\n",
      "\n",
      "old epsilon: 0.5 \n",
      "\n",
      "new epsilon: 0.5\n",
      "\n",
      "Average states alive:  29.28265642151482 \n",
      "\n",
      "*********  Elapsed time: 282.9991943836212 seconds  *************\n",
      "\n",
      "------Epsilon decays after 56.790316581726074 seconds since last decay-----\n",
      "\n",
      "old epsilon: 0.5 \n",
      "\n",
      "new epsilon: 0.5\n",
      "\n",
      "Average states alive:  28.932843651626442 \n",
      "\n",
      "*********  Elapsed time: 339.62791895866394 seconds  *************\n",
      "\n",
      "------Epsilon decays after 56.628724575042725 seconds since last decay-----\n",
      "\n",
      "old epsilon: 0.5 \n",
      "\n",
      "new epsilon: 0.5\n",
      "\n",
      "Average states alive:  26.771428571428572 \n",
      "\n",
      "*********  Elapsed time: 395.95269751548767 seconds  *************\n",
      "\n",
      "------Epsilon decays after 56.32477855682373 seconds since last decay-----\n",
      "\n",
      "old epsilon: 0.5 \n",
      "\n",
      "new epsilon: 0.5\n",
      "\n",
      "Average states alive:  26.86628909135681 \n",
      "\n",
      "*********  Elapsed time: 452.86153650283813 seconds  *************\n",
      "\n",
      "------Epsilon decays after 56.908838987350464 seconds since last decay-----\n",
      "\n",
      "old epsilon: 0.5 \n",
      "\n",
      "new epsilon: 0.5\n",
      "\n",
      "Average states alive:  27.388349514563107 \n",
      "\n",
      "*********  Elapsed time: 509.2404854297638 seconds  *************\n",
      "\n",
      "------Epsilon decays after 56.37894892692566 seconds since last decay-----\n",
      "\n",
      "old epsilon: 0.5 \n",
      "\n",
      "new epsilon: 0.5\n",
      "\n",
      "Average states alive:  26.88233812043336 \n",
      "\n",
      "*********  Elapsed time: 565.7830910682678 seconds  *************\n",
      "\n",
      "------Epsilon decays after 56.54260563850403 seconds since last decay-----\n",
      "\n",
      "old epsilon: 0.5 \n",
      "\n",
      "new epsilon: 0.5\n",
      "\n",
      "Average states alive:  27.0143815915628 \n",
      "\n",
      "*********  Elapsed time: 622.6914117336273 seconds  *************\n",
      "\n",
      "------Epsilon decays after 56.90728402137756 seconds since last decay-----\n",
      "\n",
      "old epsilon: 0.5 \n",
      "\n",
      "new epsilon: 0.5\n",
      "\n",
      "Average states alive:  27.804585152838428 \n",
      "\n",
      "*********  Elapsed time: 679.5387206077576 seconds  *************\n",
      "\n",
      "------Epsilon decays after 56.84730887413025 seconds since last decay-----\n",
      "\n",
      "old epsilon: 0.5 \n",
      "\n",
      "new epsilon: 0.5\n",
      "\n",
      "Average states alive:  26.552932587004136 \n",
      "\n",
      "*********  Elapsed time: 735.9120976924896 seconds  *************\n",
      "\n",
      "------Epsilon decays after 56.373377084732056 seconds since last decay-----\n",
      "\n",
      "old epsilon: 0.5 \n",
      "\n",
      "new epsilon: 0.5\n",
      "\n",
      "Average states alive:  27.059758912541678 \n",
      "\n",
      "*********  Elapsed time: 792.8322501182556 seconds  *************\n",
      "\n",
      "------Epsilon decays after 56.92015242576599 seconds since last decay-----\n",
      "\n",
      "old epsilon: 0.5 \n",
      "\n",
      "new epsilon: 0.5\n",
      "\n",
      "Average states alive:  26.796671866874675 \n",
      "\n",
      "*********  Elapsed time: 849.602135181427 seconds  *************\n",
      "\n",
      "------Epsilon decays after 56.768885374069214 seconds since last decay-----\n",
      "\n",
      "old epsilon: 0.5 \n",
      "\n",
      "new epsilon: 0.5\n",
      "\n",
      "Average states alive:  26.314166231050706 \n",
      "\n",
      "*****stopped training after 900.1560077667236 seconds*****\n",
      "\n",
      "*****Plot filters in first layer*****\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Pickle Dumping model*****\n",
      "\n",
      "*****Saving model*****\n"
     ]
    }
   ],
   "source": [
    "#initialize environment\n",
    "env = gym.make(\"CartPole-v1\",render_mode=\"rgb_array\")\n",
    "#preprocess environment\n",
    "#env = gym.wrappers.AtariPreprocessing(env, screen_size=84, grayscale_obs=True, frame_skip=1, noop_max=30, scale_obs = True)\n",
    "#start environment\n",
    "state, info = env.reset()\n",
    "#create action array\n",
    "actions = range(env.action_space.n)\n",
    "\n",
    "#hyperparams\n",
    "epsilon = 1\n",
    "epsilon_decay = 0.9\n",
    "gamma = 0.75\n",
    "experience_capacity = 2400\n",
    "training_freq = 200\n",
    "copying_freq = 800\n",
    "samples_per_training_session = 100\n",
    "samples_per_batch = 20\n",
    "\n",
    "#initialize agent\n",
    "agent = DQN_agent()\n",
    "#agent.pred_NN.train(mode=False)\n",
    "#agent.target_NN.train(mode=False)\n",
    "\n",
    "#load saved model to agent NNs\n",
    "#agent.pred_NN.load_state_dict(torch.load(\"model\"))\n",
    "#agent.target_NN = copy.deepcopy(agent.pred_NN)\n",
    "\n",
    "#select first action\n",
    "action = random.choice(actions)\n",
    "print('action: ', action)\n",
    "\n",
    "#get first states\n",
    "state1, reward, terminated, truncated, info = env.step(action)\n",
    "state1 = torch.from_numpy(state1)\n",
    "#state2, reward, terminated, truncated, info = env.step(action)\n",
    "#state3, reward, terminated, truncated, info = env.step(action)\n",
    "#state4, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "#convert first states to correct datatype and stack\n",
    "#state1 = TF.to_tensor(state1)     \n",
    "#state2 = TF.to_tensor(state2)\n",
    "#state3 = TF.to_tensor(state3)\n",
    "#state4 = TF.to_tensor(state4)\n",
    "#state_stack = torch.cat((state1,state2,state3,state4))\n",
    "#state_stack = torch.unsqueeze(state_stack, 0)\n",
    "\n",
    "#plot image, to se resolution\n",
    "#img = state4.permute(1, 2, 0).numpy()\n",
    "#plt.imshow(img)\n",
    "#plt.show()\n",
    "\n",
    "print('Plot filters in first layer\\n')\n",
    "#kernels = agent.pred_NN.stack[0].weight.detach().clone()\n",
    "#kernels = kernels - kernels.min()\n",
    "#kernels = kernels / kernels.max()\n",
    "#filter_img = torchvision.utils.make_grid(kernels, nrow = 8)\n",
    "#plt.imshow(filter_img.permute(1, 2, 0))\n",
    "#plt.show() \n",
    "\n",
    "#timer and variables connected to time\n",
    "start_time = time.time()\n",
    "epsilon_start_time = time.time()\n",
    "elapsed_time = 0\n",
    "max_time = 2000\n",
    "training_time = 0\n",
    "decay_freq = max_time/16\n",
    "\n",
    "#for logging\n",
    "training_session = 0\n",
    "\n",
    "\n",
    "#loops until max_time is reached\n",
    "while elapsed_time < max_time:\n",
    "    experiences = []\n",
    "    #print(f'*********  Elapsed time: {elapsed_time} seconds  *************\\n')\n",
    "    #loops until experience_capacity is reached\n",
    "    for i in range(1, experience_capacity):\n",
    "        \n",
    "    \n",
    "        #predict q-values and choose action\n",
    "        pred = agent.predict(state1)\n",
    "        #pred = pred.squeeze()\n",
    "        action = agent.action(pred)\n",
    "        #if action == 0:\n",
    "            #print('state: ', state1 , '\\n', 'action: ', 'left')\n",
    "        #if action == 1:\n",
    "            #print('state: ', state1 , '\\n', 'action: ', 'right')\n",
    "        \n",
    "        #get next states\n",
    "        next_state1, reward1, terminated, truncated, info = env.step(action)\n",
    "        #next_state2, reward2, terminated, truncated, info = env.step(action)\n",
    "        #next_state3, reward3, terminated, truncated, info = env.step(action)\n",
    "        #next_state4, reward4, terminated, truncated, info = env.step(action)\n",
    "        states_alive += 1\n",
    "        #if pac-man dies 4 times, reset and start again\n",
    "        if terminated or truncated:\n",
    "            states_alive_list.append(states_alive)\n",
    "            states_alive = 0\n",
    "            #print('terminated:', terminated, 'truncated: ', truncated)\n",
    "            #restart pacman\n",
    "            env.reset()\n",
    "            #select first action\n",
    "            action = random.choice(actions)\n",
    "            #get first states\n",
    "            next_state1, reward1, terminated, truncated, info = env.step(action)\n",
    "            #next_state2, reward2, terminated, truncated, info = env.step(action)\n",
    "            #next_state3, reward3, terminated, truncated, info = env.step(action)\n",
    "            #next_state4, reward4, terminated, truncated, info = env.step(action)\n",
    "            \n",
    "        #convert next state to correct type and stack\n",
    "        #next_state1 = TF.to_tensor(next_state1)\n",
    "        next_state1 = torch.from_numpy(next_state1)\n",
    "        #next_state2 = TF.to_tensor(next_state2)\n",
    "        #next_state3 = TF.to_tensor(next_state3)\n",
    "        #next_state4 = TF.to_tensor(next_state4)\n",
    "        #next_state_stack = torch.cat((next_state1,next_state2,next_state3,next_state4)) \n",
    "        #next_state_stack = torch.unsqueeze(next_state_stack, 0)\n",
    "        \n",
    "        #sum rewards \n",
    "        #tot_reward = 0\n",
    "        tot_reward = reward1 #+ reward2 + reward3 + reward4\n",
    "        \n",
    "        #add to experiences\n",
    "        save_this = [state1, action, tot_reward, next_state1] \n",
    "        experiences.append(save_this)\n",
    "        \n",
    "        #train\n",
    "        if i % training_freq == 0:\n",
    "            training_session += 1\n",
    "            #print(f'-----Training {training_session}-----')\n",
    "            elapsed_time = time.time() - start_time\n",
    "            #print(f'Elapsed time: {elapsed_time} seconds')\n",
    "            experiences_train = random.choices(experiences, k=samples_per_training_session)\n",
    "            epoch_loss = agent.train(experiences_train)\n",
    "            #print(\"Epoch loss: \", epoch_loss, \"\\n\")  \n",
    "            \n",
    "        #copy\n",
    "        if i % copying_freq == 0:\n",
    "            #print('-----Copying pred_NN to target_NN-----\\n')\n",
    "            agent.copy()\n",
    "            elapsed_time = time.time() - start_time\n",
    "            if elapsed_time > max_time:\n",
    "                break\n",
    "                \n",
    "        #next state stack becomes current state stack\n",
    "        #state_stack = next_state_stack\n",
    "        state1 = next_state1\n",
    "            \n",
    "        \n",
    "    #decay epsilon\n",
    "    if(epsilon > 0.2 and (time.time() - epsilon_start_time) > decay_freq):\n",
    "        elapsed_time = time.time() - start_time\n",
    "        print(f'*********  Elapsed time: {elapsed_time} seconds  *************\\n')\n",
    "        print(f'------Epsilon decays after {(time.time() - epsilon_start_time)} seconds since last decay-----\\n')\n",
    "        print(f'old epsilon: {epsilon} \\n')\n",
    "        epsilon = epsilon * epsilon_decay \n",
    "        print(f'new epsilon: {epsilon}\\n')\n",
    "        average_states_alive = sum(states_alive_list)/len(states_alive_list)\n",
    "        print('Average states alive: ', average_states_alive, '\\n')\n",
    "        states_alive = 0\n",
    "        states_alive_list = []\n",
    "        epsilon_start_time = time.time()\n",
    "        \n",
    "\n",
    "print(f'*****stopped training after {elapsed_time} seconds*****\\n')\n",
    "\n",
    "print('*****Plot filters in first layer*****\\n')\n",
    "kernels = agent.pred_NN.stack[0].weight.detach().clone()\n",
    "kernels = kernels - kernels.min()\n",
    "kernels = kernels / kernels.max()\n",
    "filter_img = torchvision.utils.make_grid(kernels, nrow = 8)\n",
    "plt.imshow(filter_img.permute(1, 2, 0))\n",
    "plt.show() \n",
    "\n",
    "print('*****Pickle Dumping model*****\\n')\n",
    "\n",
    "file = open('safetyPickleDump', 'wb')\n",
    "pickle.dump(agent, file)\n",
    "file.close()\n",
    "\n",
    "print(\"*****Saving model*****\")\n",
    "torch.save(agent.pred_NN.state_dict(), \"model\")\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a28df9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e6d71b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543cfb39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
