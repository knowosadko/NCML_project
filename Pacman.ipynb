{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "12eac9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ale_py\n",
    "import shimmy\n",
    "import gymnasium as gym\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, random_split, Dataset\n",
    "from torch.nn import functional as F\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "import os\n",
    "import random\n",
    "import copy\n",
    "import time\n",
    "import pickle\n",
    "import torcheck\n",
    "import torchvision\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e6c9d7",
   "metadata": {},
   "source": [
    "# NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "343f5217",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CNN(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()   \n",
    "        \n",
    "        self.stack = torch.nn.Sequential(\n",
    "            nn.Conv2d(4, 32, kernel_size=8, stride=4, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=0),\n",
    "            nn.Flatten(),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(3136, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 5)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.stack(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bee889c",
   "metadata": {},
   "source": [
    "# Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "1bdb7991",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN_agent:\n",
    "\n",
    "    def __init__(self):\n",
    "        # Get cpu, gpu or mps device for training.\n",
    "        self.device = (\n",
    "            \"cuda\"\n",
    "            if torch.cuda.is_available()\n",
    "            else \"mps\"\n",
    "            if torch.backends.mps.is_available()\n",
    "            else \"cpu\"\n",
    "        )\n",
    "        print(f\"Using {self.device} device\")\n",
    "        self.pred_NN = CNN().to(self.device)\n",
    "        self.target_NN = copy.deepcopy(self.pred_NN)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        pred = self.pred_NN.forward(x)\n",
    "        return pred\n",
    "    \n",
    "    def action(self, pred):\n",
    "        if random.random() < epsilon:\n",
    "            action = random.randint(0, pred.size(dim=0) - 1)\n",
    "        else: \n",
    "            action = torch.argmax(pred)\n",
    "        return action\n",
    "    \n",
    "    def train(self, experiences):\n",
    "      \n",
    "        data_set = ExperiencesDataset(experiences, self)\n",
    "        data_loader = DataLoader(data_set, batch_size=samples_per_batch, shuffle=True)\n",
    "        optimizer = torch.optim.SGD(self.pred_NN.parameters(), lr=0.1)\n",
    "        loss_fn = nn.MSELoss()\n",
    "        epoch_loss = 0\n",
    "        \n",
    "        self.pred_NN.train()\n",
    "\n",
    "        torcheck.register(optimizer)\n",
    "        torcheck.add_module_changing_check(self.pred_NN, module_name=\"my_model\")\n",
    "        \n",
    "        for batch, (state, y) in enumerate(data_loader):\n",
    "            \n",
    "            pred = self.pred_NN(state)\n",
    "            loss = loss_fn(pred, y)\n",
    "            \n",
    "            loss.backward(retain_graph=True)\n",
    "            #print('****** Gradients ******')\n",
    "            #for p in self.pred_NN.parameters():\n",
    "                #print(p.grad.norm())\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            if batch == (len(data_loader) - 1):\n",
    "                self.pred_NN.train(mode=False)\n",
    "                return epoch_loss\n",
    "        \n",
    "    def copy(self):\n",
    "        self.target_NN = copy.deepcopy(self.pred_NN)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece931b1",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "7a15bb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExperiencesDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, experiences, agent):\n",
    "    \n",
    "        self.states = []\n",
    "        self.labels = []\n",
    "        \n",
    "        for n, experience in enumerate(experiences):\n",
    "            #print('**************  CREATE LABEL  ********************\\n')\n",
    "            state, action, reward, next_state = experience\n",
    "            \n",
    "            #print('STATE\\n')\n",
    "            #img = state[0].permute(1, 2, 0).numpy()\n",
    "            #plt.imshow(img)\n",
    "            #plt.show()\n",
    "            \n",
    "            #print('NEXT STATE\\n')\n",
    "            #img = next_state[0].permute(1, 2, 0).numpy()\n",
    "            #plt.imshow(img)\n",
    "            #plt.show()\n",
    "\n",
    "            #print('reward: ', reward, '\\n')\n",
    "            #print('action: ', action, '\\n')\n",
    "            \n",
    "            pred = agent.predict(state)\n",
    "            label = pred.detach().clone().squeeze()\n",
    "            \n",
    "            #print('pred: ', label, '\\n')\n",
    "            \n",
    "            target_pred = agent.target_NN.forward(next_state)\n",
    "            target_pred = target_pred.squeeze()\n",
    "            target = reward + gamma * max(target_pred)\n",
    "            \n",
    "            \n",
    "            label[action] = target\n",
    "            #print('label: ', label, '\\n')\n",
    "            \n",
    "            self.labels.append(label) \n",
    "            \n",
    "            state = state.squeeze()\n",
    "            self.states.append(state)\n",
    "            #print('********************  END  ***********************\\n')\n",
    "    def __len__(self):\n",
    "        return len(self.states)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.states[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b4a93c",
   "metadata": {},
   "source": [
    "# Run agent (main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5dce59e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Plot filters in first layer\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Training 1-----\n",
      "Elapsed time: 6.7255699634552 seconds\n",
      "Epoch loss:  2.238368086516857 \n",
      "\n",
      "-----Training 2-----\n",
      "Elapsed time: 18.285791397094727 seconds\n",
      "Epoch loss:  3.743823589757085 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 3-----\n",
      "Elapsed time: 31.2606999874115 seconds\n",
      "Epoch loss:  6.883125269785523 \n",
      "\n",
      "-----Training 4-----\n",
      "Elapsed time: 46.062785148620605 seconds\n",
      "Epoch loss:  7.007669739425182 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 5-----\n",
      "Elapsed time: 60.55208134651184 seconds\n",
      "Epoch loss:  2.0410476848483086 \n",
      "\n",
      "-----Training 6-----\n",
      "Elapsed time: 73.00623488426208 seconds\n",
      "Epoch loss:  0.453489001840353 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 7-----\n",
      "Elapsed time: 85.7750825881958 seconds\n",
      "Epoch loss:  27.062560137361288 \n",
      "\n",
      "-----Training 8-----\n",
      "Elapsed time: 100.96169662475586 seconds\n",
      "Epoch loss:  0.606380257755518 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 9-----\n",
      "Elapsed time: 114.30635023117065 seconds\n",
      "Epoch loss:  0.39180738292634487 \n",
      "\n",
      "-----Training 10-----\n",
      "Elapsed time: 135.80970740318298 seconds\n",
      "Epoch loss:  0.43972092866897583 \n",
      "\n",
      "-----Training 11-----\n",
      "Elapsed time: 148.74948382377625 seconds\n",
      "Epoch loss:  0.42229518108069897 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 12-----\n",
      "Elapsed time: 161.88950657844543 seconds\n",
      "Epoch loss:  0.41304024308919907 \n",
      "\n",
      "-----Training 13-----\n",
      "Elapsed time: 175.02225470542908 seconds\n",
      "Epoch loss:  0.5007320456206799 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 14-----\n",
      "Elapsed time: 188.40150666236877 seconds\n",
      "Epoch loss:  2.1678029587492347 \n",
      "\n",
      "-----Training 15-----\n",
      "Elapsed time: 202.4353985786438 seconds\n",
      "Epoch loss:  2.0354356188327074 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 16-----\n",
      "Elapsed time: 215.7049651145935 seconds\n",
      "Epoch loss:  0.4855304341763258 \n",
      "\n",
      "-----Training 17-----\n",
      "Elapsed time: 229.1161708831787 seconds\n",
      "Epoch loss:  0.3791489899158478 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 18-----\n",
      "Elapsed time: 242.7523169517517 seconds\n",
      "Epoch loss:  4.358918892219663 \n",
      "\n",
      "-----Training 19-----\n",
      "Elapsed time: 264.14784264564514 seconds\n",
      "Epoch loss:  0.4834697935730219 \n",
      "\n",
      "-----Training 20-----\n",
      "Elapsed time: 276.84436798095703 seconds\n",
      "Epoch loss:  0.6054538246244192 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 21-----\n",
      "Elapsed time: 290.13398003578186 seconds\n",
      "Epoch loss:  0.4675450176000595 \n",
      "\n",
      "-----Training 22-----\n",
      "Elapsed time: 303.7542703151703 seconds\n",
      "Epoch loss:  2.1804577726870775 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 23-----\n",
      "Elapsed time: 317.22731375694275 seconds\n",
      "Epoch loss:  0.8682457152754068 \n",
      "\n",
      "-----Training 24-----\n",
      "Elapsed time: 331.1988220214844 seconds\n",
      "Epoch loss:  2.277224749326706 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 25-----\n",
      "Elapsed time: 345.522376537323 seconds\n",
      "Epoch loss:  0.6424493305385113 \n",
      "\n",
      "-----Training 26-----\n",
      "Elapsed time: 362.49353671073914 seconds\n",
      "Epoch loss:  6.818778023123741 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 27-----\n",
      "Elapsed time: 376.1160237789154 seconds\n",
      "Epoch loss:  0.5104584023356438 \n",
      "\n",
      "-----Training 28-----\n",
      "Elapsed time: 399.92363381385803 seconds\n",
      "Epoch loss:  2.1943544149398804 \n",
      "\n",
      "-----Training 29-----\n",
      "Elapsed time: 415.572806596756 seconds\n",
      "Epoch loss:  2.0708319768309593 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 30-----\n",
      "Elapsed time: 446.4231901168823 seconds\n",
      "Epoch loss:  2.148738119751215 \n",
      "\n",
      "-----Training 31-----\n",
      "Elapsed time: 473.6584770679474 seconds\n",
      "Epoch loss:  0.3854723833501339 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 32-----\n",
      "Elapsed time: 488.38643860816956 seconds\n",
      "Epoch loss:  0.5914282575249672 \n",
      "\n",
      "-----Training 33-----\n",
      "Elapsed time: 506.8173625469208 seconds\n",
      "Epoch loss:  0.49838733300566673 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 34-----\n",
      "Elapsed time: 521.4825131893158 seconds\n",
      "Epoch loss:  0.47795415483415127 \n",
      "\n",
      "-----Training 35-----\n",
      "Elapsed time: 539.5604977607727 seconds\n",
      "Epoch loss:  0.4135578479617834 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 36-----\n",
      "Elapsed time: 560.8881850242615 seconds\n",
      "Epoch loss:  0.6470544505864382 \n",
      "\n",
      "-----Training 37-----\n",
      "Elapsed time: 594.924459695816 seconds\n",
      "Epoch loss:  0.7570059671998024 \n",
      "\n",
      "-----Training 38-----\n",
      "Elapsed time: 606.9156329631805 seconds\n",
      "Epoch loss:  78.81301996670663 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 39-----\n",
      "Elapsed time: 618.0046184062958 seconds\n",
      "Epoch loss:  32.955850183963776 \n",
      "\n",
      "-----Training 40-----\n",
      "Elapsed time: 629.4199593067169 seconds\n",
      "Epoch loss:  0.6959693059325218 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 41-----\n",
      "Elapsed time: 640.5851323604584 seconds\n",
      "Epoch loss:  13.611955799162388 \n",
      "\n",
      "-----Training 42-----\n",
      "Elapsed time: 652.4021022319794 seconds\n",
      "Epoch loss:  0.5992951560765505 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 43-----\n",
      "Elapsed time: 663.5559456348419 seconds\n",
      "Epoch loss:  0.4959970209747553 \n",
      "\n",
      "-----Training 44-----\n",
      "Elapsed time: 673.9993860721588 seconds\n",
      "Epoch loss:  0.5165620222687721 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 45-----\n",
      "Elapsed time: 684.7135136127472 seconds\n",
      "Epoch loss:  0.44286251068115234 \n",
      "\n",
      "-----Training 46-----\n",
      "Elapsed time: 706.1126799583435 seconds\n",
      "Epoch loss:  0.6116262171417475 \n",
      "\n",
      "-----Training 47-----\n",
      "Elapsed time: 719.1855509281158 seconds\n",
      "Epoch loss:  0.4827567106112838 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 48-----\n",
      "Elapsed time: 735.0362436771393 seconds\n",
      "Epoch loss:  2.075477948412299 \n",
      "\n",
      "-----Training 49-----\n",
      "Elapsed time: 750.2289099693298 seconds\n",
      "Epoch loss:  0.5792944096028805 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 50-----\n",
      "Elapsed time: 763.6646540164948 seconds\n",
      "Epoch loss:  0.5385605692863464 \n",
      "\n",
      "-----Training 51-----\n",
      "Elapsed time: 777.5651075839996 seconds\n",
      "Epoch loss:  9.741099083796144 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 52-----\n",
      "Elapsed time: 792.6224944591522 seconds\n",
      "Epoch loss:  0.5121731236577034 \n",
      "\n",
      "-----Training 53-----\n",
      "Elapsed time: 806.8616576194763 seconds\n",
      "Epoch loss:  8.994340471923351 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 54-----\n",
      "Elapsed time: 820.9879021644592 seconds\n",
      "Epoch loss:  0.5008508041501045 \n",
      "\n",
      "-----Training 55-----\n",
      "Elapsed time: 843.1089715957642 seconds\n",
      "Epoch loss:  0.3469087705016136 \n",
      "\n",
      "-----Training 56-----\n",
      "Elapsed time: 856.0936489105225 seconds\n",
      "Epoch loss:  0.484031205996871 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 57-----\n",
      "Elapsed time: 871.1093852519989 seconds\n",
      "Epoch loss:  0.5556560400873423 \n",
      "\n",
      "-----Training 58-----\n",
      "Elapsed time: 890.2122194766998 seconds\n",
      "Epoch loss:  0.3674919903278351 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 59-----\n",
      "Elapsed time: 904.0338909626007 seconds\n",
      "Epoch loss:  0.29037071764469147 \n",
      "\n",
      "-----Training 60-----\n",
      "Elapsed time: 918.0644154548645 seconds\n",
      "Epoch loss:  6.723539989441633 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 61-----\n",
      "Elapsed time: 932.6221017837524 seconds\n",
      "Epoch loss:  0.3007349353283644 \n",
      "\n",
      "-----Training 62-----\n",
      "Elapsed time: 946.0712394714355 seconds\n",
      "Epoch loss:  0.39935108087956905 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 63-----\n",
      "Elapsed time: 960.0158579349518 seconds\n",
      "Epoch loss:  0.3846057076007128 \n",
      "\n",
      "-----Training 64-----\n",
      "Elapsed time: 987.531067609787 seconds\n",
      "Epoch loss:  2.0498475898057222 \n",
      "\n",
      "-----Training 65-----\n",
      "Elapsed time: 1003.9933352470398 seconds\n",
      "Epoch loss:  2.0219078101217747 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 66-----\n",
      "Elapsed time: 1017.381227016449 seconds\n",
      "Epoch loss:  0.4638530518859625 \n",
      "\n",
      "-----Training 67-----\n",
      "Elapsed time: 1031.4161276817322 seconds\n",
      "Epoch loss:  0.3966107703745365 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 68-----\n",
      "Elapsed time: 1047.0591650009155 seconds\n",
      "Epoch loss:  0.625806787982583 \n",
      "\n",
      "-----Training 69-----\n",
      "Elapsed time: 1063.7079429626465 seconds\n",
      "Epoch loss:  0.3903859481215477 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 70-----\n",
      "Elapsed time: 1079.284071445465 seconds\n",
      "Epoch loss:  0.4703235812485218 \n",
      "\n",
      "-----Training 71-----\n",
      "Elapsed time: 1094.5124230384827 seconds\n",
      "Epoch loss:  2.266058225184679 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 72-----\n",
      "Elapsed time: 1108.490752696991 seconds\n",
      "Epoch loss:  2.0175193771719933 \n",
      "\n",
      "-----Training 73-----\n",
      "Elapsed time: 1138.7531225681305 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch loss:  6.81874858494848 \n",
      "\n",
      "-----Training 74-----\n",
      "Elapsed time: 1151.6670203208923 seconds\n",
      "Epoch loss:  1.9729659017175436 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 75-----\n",
      "Elapsed time: 1164.9669017791748 seconds\n",
      "Epoch loss:  0.6045370325446129 \n",
      "\n",
      "-----Training 76-----\n",
      "Elapsed time: 1178.3125488758087 seconds\n",
      "Epoch loss:  0.3672059429809451 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 77-----\n",
      "Elapsed time: 1192.09730219841 seconds\n",
      "Epoch loss:  0.47120993211865425 \n",
      "\n",
      "-----Training 78-----\n",
      "Elapsed time: 1206.318210363388 seconds\n",
      "Epoch loss:  2.0016326662153006 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 79-----\n",
      "Elapsed time: 1222.5253686904907 seconds\n",
      "Epoch loss:  0.4921101648360491 \n",
      "\n",
      "-----Training 80-----\n",
      "Elapsed time: 1235.9864926338196 seconds\n",
      "Epoch loss:  0.46275671012699604 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 81-----\n",
      "Elapsed time: 1249.6194868087769 seconds\n",
      "Epoch loss:  0.5017758775502443 \n",
      "\n",
      "-----Training 82-----\n",
      "Elapsed time: 1271.4220235347748 seconds\n",
      "Epoch loss:  0.40517355501651764 \n",
      "\n",
      "-----Training 83-----\n",
      "Elapsed time: 1284.622288942337 seconds\n",
      "Epoch loss:  0.6564243920147419 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 84-----\n",
      "Elapsed time: 1297.8523228168488 seconds\n",
      "Epoch loss:  0.5498264171183109 \n",
      "\n",
      "-----Training 85-----\n",
      "Elapsed time: 1311.7139432430267 seconds\n",
      "Epoch loss:  0.47197828255593777 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 86-----\n",
      "Elapsed time: 1325.760597705841 seconds\n",
      "Epoch loss:  0.4365947004407644 \n",
      "\n",
      "-----Training 87-----\n",
      "Elapsed time: 1339.965371131897 seconds\n",
      "Epoch loss:  0.4350206181406975 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 88-----\n",
      "Elapsed time: 1352.0730357170105 seconds\n",
      "Epoch loss:  0.34199557453393936 \n",
      "\n",
      "-----Training 89-----\n",
      "Elapsed time: 1364.9712336063385 seconds\n",
      "Epoch loss:  0.4058362888172269 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 90-----\n",
      "Elapsed time: 1380.01846241951 seconds\n",
      "Epoch loss:  0.4915679283440113 \n",
      "\n",
      "-----Training 91-----\n",
      "Elapsed time: 1398.7375707626343 seconds\n",
      "Epoch loss:  0.4583391584455967 \n",
      "\n",
      "-----Training 92-----\n",
      "Elapsed time: 1416.1193358898163 seconds\n",
      "Epoch loss:  0.47262641601264477 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 93-----\n",
      "Elapsed time: 1435.071852684021 seconds\n",
      "Epoch loss:  0.37734443321824074 \n",
      "\n",
      "-----Training 94-----\n",
      "Elapsed time: 1453.498780965805 seconds\n",
      "Epoch loss:  0.5167121309787035 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 95-----\n",
      "Elapsed time: 1470.447903394699 seconds\n",
      "Epoch loss:  0.4913591556251049 \n",
      "\n",
      "-----Training 96-----\n",
      "Elapsed time: 1489.3777706623077 seconds\n",
      "Epoch loss:  0.46112428046762943 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 97-----\n",
      "Elapsed time: 1504.558270931244 seconds\n",
      "Epoch loss:  0.4180732984095812 \n",
      "\n",
      "-----Training 98-----\n",
      "Elapsed time: 1518.3219194412231 seconds\n",
      "Epoch loss:  0.4096036124974489 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 99-----\n",
      "Elapsed time: 1532.6185235977173 seconds\n",
      "Epoch loss:  6.823949670419097 \n",
      "\n",
      "-----Training 100-----\n",
      "Elapsed time: 1555.4738125801086 seconds\n",
      "Epoch loss:  0.4725344404578209 \n",
      "\n",
      "-----Training 101-----\n",
      "Elapsed time: 1568.3939607143402 seconds\n",
      "Epoch loss:  0.5733954627066851 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 102-----\n",
      "Elapsed time: 1581.7424216270447 seconds\n",
      "Epoch loss:  0.7488355971872807 \n",
      "\n",
      "-----Training 103-----\n",
      "Elapsed time: 1595.3316564559937 seconds\n",
      "Epoch loss:  0.3650715611875057 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 104-----\n",
      "Elapsed time: 1609.4255440235138 seconds\n",
      "Epoch loss:  0.6397867929190397 \n",
      "\n",
      "-----Training 105-----\n",
      "Elapsed time: 1623.881370306015 seconds\n",
      "Epoch loss:  0.5432966984808445 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 106-----\n",
      "Elapsed time: 1637.9686617851257 seconds\n",
      "Epoch loss:  0.6606018468737602 \n",
      "\n",
      "-----Training 107-----\n",
      "Elapsed time: 1651.944149017334 seconds\n",
      "Epoch loss:  0.43417140282690525 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 108-----\n",
      "Elapsed time: 1665.6193416118622 seconds\n",
      "Epoch loss:  0.4420916875824332 \n",
      "\n",
      "-----Training 109-----\n",
      "Elapsed time: 1688.3727660179138 seconds\n",
      "Epoch loss:  0.3387659452855587 \n",
      "\n",
      "-----Training 110-----\n",
      "Elapsed time: 1701.588259935379 seconds\n",
      "Epoch loss:  0.29641403909772635 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 111-----\n",
      "Elapsed time: 1715.019831418991 seconds\n",
      "Epoch loss:  0.4116556290537119 \n",
      "\n",
      "-----Training 112-----\n",
      "Elapsed time: 1728.580063343048 seconds\n",
      "Epoch loss:  0.44179748743772507 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 113-----\n",
      "Elapsed time: 1743.3748078346252 seconds\n",
      "Epoch loss:  0.5853063091635704 \n",
      "\n",
      "-----Training 114-----\n",
      "Elapsed time: 1758.5505561828613 seconds\n",
      "Epoch loss:  0.3628910221159458 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 115-----\n",
      "Elapsed time: 1772.741929769516 seconds\n",
      "Epoch loss:  2.08670842833817 \n",
      "\n",
      "-----Training 116-----\n",
      "Elapsed time: 1786.2694301605225 seconds\n",
      "Epoch loss:  0.43118226155638695 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 117-----\n",
      "Elapsed time: 1800.3659510612488 seconds\n",
      "Epoch loss:  0.39348042756319046 \n",
      "\n",
      "-----Training 118-----\n",
      "Elapsed time: 1822.8057644367218 seconds\n",
      "Epoch loss:  2.261623041704297 \n",
      "\n",
      "-----Training 119-----\n",
      "Elapsed time: 1836.5777053833008 seconds\n",
      "Epoch loss:  0.36465513333678246 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 120-----\n",
      "Elapsed time: 1851.4977419376373 seconds\n",
      "Epoch loss:  10.528336249291897 \n",
      "\n",
      "-----Training 121-----\n",
      "Elapsed time: 1867.0831599235535 seconds\n",
      "Epoch loss:  0.42488088831305504 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 122-----\n",
      "Elapsed time: 1881.663682937622 seconds\n",
      "Epoch loss:  8.398416763171554 \n",
      "\n",
      "-----Training 123-----\n",
      "Elapsed time: 1898.4786360263824 seconds\n",
      "Epoch loss:  0.565515911206603 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 124-----\n",
      "Elapsed time: 1915.0246043205261 seconds\n",
      "Epoch loss:  134.47167255356908 \n",
      "\n",
      "-----Training 125-----\n",
      "Elapsed time: 1929.06898188591 seconds\n",
      "Epoch loss:  104.78829947113991 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 126-----\n",
      "Elapsed time: 1945.1441979408264 seconds\n",
      "Epoch loss:  6.957562914118171 \n",
      "\n",
      "-----Training 127-----\n",
      "Elapsed time: 1968.0394246578217 seconds\n",
      "Epoch loss:  0.5335739850997925 \n",
      "\n",
      "-----Training 128-----\n",
      "Elapsed time: 1980.9322474002838 seconds\n",
      "Epoch loss:  2.1932384334504604 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 129-----\n",
      "Elapsed time: 1994.1808824539185 seconds\n",
      "Epoch loss:  0.5488839671015739 \n",
      "\n",
      "-----Training 130-----\n",
      "Elapsed time: 2007.9969394207 seconds\n",
      "Epoch loss:  2.068300588056445 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 131-----\n",
      "Elapsed time: 2021.8506321907043 seconds\n",
      "Epoch loss:  2.0049229506403208 \n",
      "\n",
      "-----Training 132-----\n",
      "Elapsed time: 2036.1912815570831 seconds\n",
      "Epoch loss:  0.7171784788370132 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 133-----\n",
      "Elapsed time: 2050.3485021591187 seconds\n",
      "Epoch loss:  0.447656013071537 \n",
      "\n",
      "-----Training 134-----\n",
      "Elapsed time: 2063.9813590049744 seconds\n",
      "Epoch loss:  2.0687287766486406 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 135-----\n",
      "Elapsed time: 2077.5992815494537 seconds\n",
      "Epoch loss:  2.0740853808820248 \n",
      "\n",
      "-----Training 136-----\n",
      "Elapsed time: 2103.2770121097565 seconds\n",
      "Epoch loss:  0.47267381474375725 \n",
      "\n",
      "-----Training 137-----\n",
      "Elapsed time: 2117.6408290863037 seconds\n",
      "Epoch loss:  0.40024346113204956 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 138-----\n",
      "Elapsed time: 2131.8124084472656 seconds\n",
      "Epoch loss:  26.352437760680914 \n",
      "\n",
      "-----Training 139-----\n",
      "Elapsed time: 2145.9594740867615 seconds\n",
      "Epoch loss:  0.5618022847920656 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 140-----\n",
      "Elapsed time: 2160.354614496231 seconds\n",
      "Epoch loss:  0.43820606730878353 \n",
      "\n",
      "-----Training 141-----\n",
      "Elapsed time: 2174.883173942566 seconds\n",
      "Epoch loss:  0.40928562358021736 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 142-----\n",
      "Elapsed time: 2191.738899707794 seconds\n",
      "Epoch loss:  2.3077793307602406 \n",
      "\n",
      "-----Training 143-----\n",
      "Elapsed time: 2206.289426088333 seconds\n",
      "Epoch loss:  26.003710748627782 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 144-----\n",
      "Elapsed time: 2220.1625514030457 seconds\n",
      "Epoch loss:  1.9393432457000017 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Training 145-----\n",
      "Elapsed time: 2242.441892385483 seconds\n",
      "Epoch loss:  0.32261792477220297 \n",
      "\n",
      "-----Training 146-----\n",
      "Elapsed time: 2259.596221446991 seconds\n",
      "Epoch loss:  0.6136724781244993 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 147-----\n",
      "Elapsed time: 2273.75177025795 seconds\n",
      "Epoch loss:  0.7491069938987494 \n",
      "\n",
      "-----Training 148-----\n",
      "Elapsed time: 2289.4107933044434 seconds\n",
      "Epoch loss:  0.44330400601029396 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 149-----\n",
      "Elapsed time: 2306.9350485801697 seconds\n",
      "Epoch loss:  0.5102329645305872 \n",
      "\n",
      "-----Training 150-----\n",
      "Elapsed time: 2321.0703241825104 seconds\n",
      "Epoch loss:  0.47397059202194214 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 151-----\n",
      "Elapsed time: 2335.9414060115814 seconds\n",
      "Epoch loss:  0.4603878017514944 \n",
      "\n",
      "-----Training 152-----\n",
      "Elapsed time: 2349.4484901428223 seconds\n",
      "Epoch loss:  0.492008987814188 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 153-----\n",
      "Elapsed time: 2363.2325789928436 seconds\n",
      "Epoch loss:  0.39477909356355667 \n",
      "\n",
      "-----Training 154-----\n",
      "Elapsed time: 2384.0271451473236 seconds\n",
      "Epoch loss:  0.3174762949347496 \n",
      "\n",
      "-----Training 155-----\n",
      "Elapsed time: 2394.8147134780884 seconds\n",
      "Epoch loss:  0.579866636544466 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 156-----\n",
      "Elapsed time: 2405.9018030166626 seconds\n",
      "Epoch loss:  40.285945285111666 \n",
      "\n",
      "-----Training 157-----\n",
      "Elapsed time: 2417.282781600952 seconds\n",
      "Epoch loss:  0.4144417494535446 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 158-----\n",
      "Elapsed time: 2428.604825735092 seconds\n",
      "Epoch loss:  0.4158874452114105 \n",
      "\n",
      "-----Training 159-----\n",
      "Elapsed time: 2440.366030216217 seconds\n",
      "Epoch loss:  0.47582441195845604 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 160-----\n",
      "Elapsed time: 2452.161379337311 seconds\n",
      "Epoch loss:  0.4098006393760443 \n",
      "\n",
      "-----Training 161-----\n",
      "Elapsed time: 2464.53635764122 seconds\n",
      "Epoch loss:  40.29705978743732 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 162-----\n",
      "Elapsed time: 2475.680545568466 seconds\n",
      "Epoch loss:  2.1549809090793133 \n",
      "\n",
      "-----Training 163-----\n",
      "Elapsed time: 2494.606456518173 seconds\n",
      "Epoch loss:  0.3971449229866266 \n",
      "\n",
      "-----Training 164-----\n",
      "Elapsed time: 2507.8775589466095 seconds\n",
      "Epoch loss:  0.4012469332665205 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 165-----\n",
      "Elapsed time: 2521.6076834201813 seconds\n",
      "Epoch loss:  0.3639793675392866 \n",
      "\n",
      "-----Training 166-----\n",
      "Elapsed time: 2535.461743116379 seconds\n",
      "Epoch loss:  0.576310059055686 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 167-----\n",
      "Elapsed time: 2549.72248005867 seconds\n",
      "Epoch loss:  0.39172335900366306 \n",
      "\n",
      "-----Training 168-----\n",
      "Elapsed time: 2564.084738969803 seconds\n",
      "Epoch loss:  0.3846828658133745 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 169-----\n",
      "Elapsed time: 2578.7031786441803 seconds\n",
      "Epoch loss:  0.49637041613459587 \n",
      "\n",
      "-----Training 170-----\n",
      "Elapsed time: 2592.6964695453644 seconds\n",
      "Epoch loss:  0.47506647929549217 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 171-----\n",
      "Elapsed time: 2606.8264100551605 seconds\n",
      "Epoch loss:  0.38107482716441154 \n",
      "\n",
      "------Epsilon decays after 2621.0961821079254 seconds since last decay-----\n",
      "\n",
      "old epsilon: 1 \n",
      "\n",
      "new epsilon: 0.9\n",
      "\n",
      "-----Training 172-----\n",
      "Elapsed time: 2629.320079565048 seconds\n",
      "Epoch loss:  2.3735650815069675 \n",
      "\n",
      "-----Training 173-----\n",
      "Elapsed time: 2642.48769903183 seconds\n",
      "Epoch loss:  4.6582244746387005 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 174-----\n",
      "Elapsed time: 2655.930770635605 seconds\n",
      "Epoch loss:  53.412303423509 \n",
      "\n",
      "-----Training 175-----\n",
      "Elapsed time: 2670.4376645088196 seconds\n",
      "Epoch loss:  0.4942373801022768 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 176-----\n",
      "Elapsed time: 2684.402085542679 seconds\n",
      "Epoch loss:  0.7039657440036535 \n",
      "\n",
      "-----Training 177-----\n",
      "Elapsed time: 2698.821357488632 seconds\n",
      "Epoch loss:  1.9671830479055643 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 178-----\n",
      "Elapsed time: 2713.361471414566 seconds\n",
      "Epoch loss:  0.5002851691097021 \n",
      "\n",
      "-----Training 179-----\n",
      "Elapsed time: 2727.7759478092194 seconds\n",
      "Epoch loss:  0.45722561702132225 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 180-----\n",
      "Elapsed time: 2741.885793685913 seconds\n",
      "Epoch loss:  0.567442262545228 \n",
      "\n",
      "-----Training 181-----\n",
      "Elapsed time: 2764.6808698177338 seconds\n",
      "Epoch loss:  3.6678949669003487 \n",
      "\n",
      "-----Training 182-----\n",
      "Elapsed time: 2777.954149246216 seconds\n",
      "Epoch loss:  0.44375873170793056 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 183-----\n",
      "Elapsed time: 2791.392035961151 seconds\n",
      "Epoch loss:  3.687124527990818 \n",
      "\n",
      "-----Training 184-----\n",
      "Elapsed time: 2804.990115880966 seconds\n",
      "Epoch loss:  0.33302865363657475 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 185-----\n",
      "Elapsed time: 2818.9626762866974 seconds\n",
      "Epoch loss:  2.190803550183773 \n",
      "\n",
      "-----Training 186-----\n",
      "Elapsed time: 2834.7794485092163 seconds\n",
      "Epoch loss:  0.5624436214566231 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 187-----\n",
      "Elapsed time: 2850.5372173786163 seconds\n",
      "Epoch loss:  0.4111264366656542 \n",
      "\n",
      "-----Training 188-----\n",
      "Elapsed time: 2864.9906120300293 seconds\n",
      "Epoch loss:  2.0178271997720003 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 189-----\n",
      "Elapsed time: 2879.3703696727753 seconds\n",
      "Epoch loss:  0.6112334318459034 \n",
      "\n",
      "-----Training 190-----\n",
      "Elapsed time: 2930.3788430690765 seconds\n",
      "Epoch loss:  2.06316651776433 \n",
      "\n",
      "-----Training 191-----\n",
      "Elapsed time: 2949.792576313019 seconds\n",
      "Epoch loss:  0.5778836309909821 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 192-----\n",
      "Elapsed time: 2964.7972750663757 seconds\n",
      "Epoch loss:  0.5922147845849395 \n",
      "\n",
      "-----Training 193-----\n",
      "Elapsed time: 2978.529856443405 seconds\n",
      "Epoch loss:  2.0131918266415596 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 194-----\n",
      "Elapsed time: 2993.0501182079315 seconds\n",
      "Epoch loss:  0.32425086945295334 \n",
      "\n",
      "-----Training 195-----\n",
      "Elapsed time: 3007.3901410102844 seconds\n",
      "Epoch loss:  0.4600905068218708 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 196-----\n",
      "Elapsed time: 3022.040709733963 seconds\n",
      "Epoch loss:  0.42034200578927994 \n",
      "\n",
      "-----Training 197-----\n",
      "Elapsed time: 3036.464023590088 seconds\n",
      "Epoch loss:  0.40291013568639755 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 198-----\n",
      "Elapsed time: 3050.541115999222 seconds\n",
      "Epoch loss:  0.5027948636561632 \n",
      "\n",
      "-----Training 199-----\n",
      "Elapsed time: 3072.901214361191 seconds\n",
      "Epoch loss:  0.4790183650329709 \n",
      "\n",
      "-----Training 200-----\n",
      "Elapsed time: 3085.8188512325287 seconds\n",
      "Epoch loss:  2.0005783904343843 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 201-----\n",
      "Elapsed time: 3098.997997045517 seconds\n",
      "Epoch loss:  0.3344728425145149 \n",
      "\n",
      "-----Training 202-----\n",
      "Elapsed time: 3112.7376458644867 seconds\n",
      "Epoch loss:  2.0276697892695665 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 203-----\n",
      "Elapsed time: 3126.999797105789 seconds\n",
      "Epoch loss:  3.5629182308912277 \n",
      "\n",
      "-----Training 204-----\n",
      "Elapsed time: 3141.5176372528076 seconds\n",
      "Epoch loss:  2.021496130153537 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 205-----\n",
      "Elapsed time: 3156.027774810791 seconds\n",
      "Epoch loss:  0.5204306747764349 \n",
      "\n",
      "-----Training 206-----\n",
      "Elapsed time: 3170.232634305954 seconds\n",
      "Epoch loss:  2.015335602685809 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 207-----\n",
      "Elapsed time: 3184.275990962982 seconds\n",
      "Epoch loss:  0.42786614410579205 \n",
      "\n",
      "-----Training 208-----\n",
      "Elapsed time: 3208.746741294861 seconds\n",
      "Epoch loss:  0.4192842524498701 \n",
      "\n",
      "-----Training 209-----\n",
      "Elapsed time: 3221.728855609894 seconds\n",
      "Epoch loss:  0.5278137177228928 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 210-----\n",
      "Elapsed time: 3235.239751815796 seconds\n",
      "Epoch loss:  13.29123942181468 \n",
      "\n",
      "-----Training 211-----\n",
      "Elapsed time: 3249.366529226303 seconds\n",
      "Epoch loss:  6.845793798565865 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 212-----\n",
      "Elapsed time: 3263.600723028183 seconds\n",
      "Epoch loss:  0.5329349115490913 \n",
      "\n",
      "-----Training 213-----\n",
      "Elapsed time: 3277.795079469681 seconds\n",
      "Epoch loss:  0.4975293502211571 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 214-----\n",
      "Elapsed time: 3292.6956634521484 seconds\n",
      "Epoch loss:  0.48321486078202724 \n",
      "\n",
      "-----Training 215-----\n",
      "Elapsed time: 3306.784430742264 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch loss:  0.4486911315470934 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 216-----\n",
      "Elapsed time: 3320.736510515213 seconds\n",
      "Epoch loss:  0.44180996529757977 \n",
      "\n",
      "-----Training 217-----\n",
      "Elapsed time: 3343.5324618816376 seconds\n",
      "Epoch loss:  0.39825023896992207 \n",
      "\n",
      "-----Training 218-----\n",
      "Elapsed time: 3356.351877450943 seconds\n",
      "Epoch loss:  0.5093014482408762 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 219-----\n",
      "Elapsed time: 3369.6843843460083 seconds\n",
      "Epoch loss:  0.40343653596937656 \n",
      "\n",
      "-----Training 220-----\n",
      "Elapsed time: 3383.5758109092712 seconds\n",
      "Epoch loss:  0.3846707995980978 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 221-----\n",
      "Elapsed time: 3397.4966123104095 seconds\n",
      "Epoch loss:  0.5362658724188805 \n",
      "\n",
      "-----Training 222-----\n",
      "Elapsed time: 3411.6386046409607 seconds\n",
      "Epoch loss:  0.5296462085098028 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 223-----\n",
      "Elapsed time: 3426.256647348404 seconds\n",
      "Epoch loss:  0.5231529921293259 \n",
      "\n",
      "-----Training 224-----\n",
      "Elapsed time: 3440.650627851486 seconds\n",
      "Epoch loss:  0.4025912173092365 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 225-----\n",
      "Elapsed time: 3454.6338624954224 seconds\n",
      "Epoch loss:  0.38444745913147926 \n",
      "\n",
      "-----Training 226-----\n",
      "Elapsed time: 3477.0707743167877 seconds\n",
      "Epoch loss:  0.4193838220089674 \n",
      "\n",
      "-----Training 227-----\n",
      "Elapsed time: 3489.910713672638 seconds\n",
      "Epoch loss:  0.36899304389953613 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 228-----\n",
      "Elapsed time: 3503.6716775894165 seconds\n",
      "Epoch loss:  0.5300151892006397 \n",
      "\n",
      "-----Training 229-----\n",
      "Elapsed time: 3517.8058593273163 seconds\n",
      "Epoch loss:  0.4386855158954859 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 230-----\n",
      "Elapsed time: 3532.195697069168 seconds\n",
      "Epoch loss:  0.518648186698556 \n",
      "\n",
      "-----Training 231-----\n",
      "Elapsed time: 3548.258667230606 seconds\n",
      "Epoch loss:  0.5671383813023567 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 232-----\n",
      "Elapsed time: 3574.4127988815308 seconds\n",
      "Epoch loss:  0.41523391380906105 \n",
      "\n",
      "-----Training 233-----\n",
      "Elapsed time: 3591.438465356827 seconds\n",
      "Epoch loss:  0.6227635592222214 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 234-----\n",
      "Elapsed time: 3610.5136024951935 seconds\n",
      "Epoch loss:  0.5118025131523609 \n",
      "\n",
      "-----Training 235-----\n",
      "Elapsed time: 3636.7367284297943 seconds\n",
      "Epoch loss:  0.5490833688527346 \n",
      "\n",
      "-----Training 236-----\n",
      "Elapsed time: 3650.9388682842255 seconds\n",
      "Epoch loss:  0.571724820882082 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 237-----\n",
      "Elapsed time: 3664.442071914673 seconds\n",
      "Epoch loss:  0.46373325958848 \n",
      "\n",
      "-----Training 238-----\n",
      "Elapsed time: 3678.337510585785 seconds\n",
      "Epoch loss:  0.48829116113483906 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 239-----\n",
      "Elapsed time: 3692.665416955948 seconds\n",
      "Epoch loss:  0.5517713446170092 \n",
      "\n",
      "-----Training 240-----\n",
      "Elapsed time: 3707.344161272049 seconds\n",
      "Epoch loss:  0.5602513151243329 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 241-----\n",
      "Elapsed time: 3722.0239808559418 seconds\n",
      "Epoch loss:  0.5685133133083582 \n",
      "\n",
      "-----Training 242-----\n",
      "Elapsed time: 3736.150132417679 seconds\n",
      "Epoch loss:  0.4316190304234624 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 243-----\n",
      "Elapsed time: 3751.083260536194 seconds\n",
      "Epoch loss:  0.512562595307827 \n",
      "\n",
      "-----Training 244-----\n",
      "Elapsed time: 3779.793612718582 seconds\n",
      "Epoch loss:  0.6386363580822945 \n",
      "\n",
      "-----Training 245-----\n",
      "Elapsed time: 3794.6792051792145 seconds\n",
      "Epoch loss:  0.42514559254050255 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 246-----\n",
      "Elapsed time: 3808.5021760463715 seconds\n",
      "Epoch loss:  0.5971073284745216 \n",
      "\n",
      "-----Training 247-----\n",
      "Elapsed time: 3822.669840335846 seconds\n",
      "Epoch loss:  0.7957717627286911 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 248-----\n",
      "Elapsed time: 3837.6955523490906 seconds\n",
      "Epoch loss:  2.1019439846277237 \n",
      "\n",
      "-----Training 249-----\n",
      "Elapsed time: 3852.009790658951 seconds\n",
      "Epoch loss:  0.5230204407125711 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 250-----\n",
      "Elapsed time: 3867.0793278217316 seconds\n",
      "Epoch loss:  2.063640832901001 \n",
      "\n",
      "-----Training 251-----\n",
      "Elapsed time: 3881.229627609253 seconds\n",
      "Epoch loss:  2.052013086155057 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 252-----\n",
      "Elapsed time: 3895.0249378681183 seconds\n",
      "Epoch loss:  0.4643788952380419 \n",
      "\n",
      "-----Training 253-----\n",
      "Elapsed time: 3917.614091157913 seconds\n",
      "Epoch loss:  0.3911459967494011 \n",
      "\n",
      "-----Training 254-----\n",
      "Elapsed time: 3930.721429824829 seconds\n",
      "Epoch loss:  0.6052573416382074 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 255-----\n",
      "Elapsed time: 3944.8319520950317 seconds\n",
      "Epoch loss:  0.46356905810534954 \n",
      "\n",
      "-----Training 256-----\n",
      "Elapsed time: 3958.8825945854187 seconds\n",
      "Epoch loss:  0.6378868445754051 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 257-----\n",
      "Elapsed time: 3974.5730950832367 seconds\n",
      "Epoch loss:  0.6296943053603172 \n",
      "\n",
      "-----Training 258-----\n",
      "Elapsed time: 3991.866481781006 seconds\n",
      "Epoch loss:  0.5389413759112358 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 259-----\n",
      "Elapsed time: 4008.6355299949646 seconds\n",
      "Epoch loss:  0.4633065536618233 \n",
      "\n",
      "-----Training 260-----\n",
      "Elapsed time: 4026.1860303878784 seconds\n",
      "Epoch loss:  0.45570072904229164 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 261-----\n",
      "Elapsed time: 4044.433606863022 seconds\n",
      "Epoch loss:  0.5061025135219097 \n",
      "\n",
      "-----Training 262-----\n",
      "Elapsed time: 4069.0128235816956 seconds\n",
      "Epoch loss:  6.951899568550289 \n",
      "\n",
      "-----Training 263-----\n",
      "Elapsed time: 4084.0914175510406 seconds\n",
      "Epoch loss:  0.6340585649013519 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 264-----\n",
      "Elapsed time: 4104.544905900955 seconds\n",
      "Epoch loss:  0.37672573886811733 \n",
      "\n",
      "-----Training 265-----\n",
      "Elapsed time: 4136.353298187256 seconds\n",
      "Epoch loss:  0.5069801192730665 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 266-----\n",
      "Elapsed time: 4163.9509382247925 seconds\n",
      "Epoch loss:  0.47843121364712715 \n",
      "\n",
      "-----Training 267-----\n",
      "Elapsed time: 4197.265146255493 seconds\n",
      "Epoch loss:  0.6353150270879269 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 268-----\n",
      "Elapsed time: 4220.69929432869 seconds\n",
      "Epoch loss:  0.528347434476018 \n",
      "\n",
      "-----Training 269-----\n",
      "Elapsed time: 4235.804301738739 seconds\n",
      "Epoch loss:  0.38607185147702694 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 270-----\n",
      "Elapsed time: 4250.587554931641 seconds\n",
      "Epoch loss:  0.573929644189775 \n",
      "\n",
      "-----Training 271-----\n",
      "Elapsed time: 4273.898869276047 seconds\n",
      "Epoch loss:  0.46409538108855486 \n",
      "\n",
      "-----Training 272-----\n",
      "Elapsed time: 4287.230432987213 seconds\n",
      "Epoch loss:  0.3933324348181486 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 273-----\n",
      "Elapsed time: 4301.120489597321 seconds\n",
      "Epoch loss:  2.148796960711479 \n",
      "\n",
      "-----Training 274-----\n",
      "Elapsed time: 4315.608169794083 seconds\n",
      "Epoch loss:  2.031823394820094 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 275-----\n",
      "Elapsed time: 4330.279238700867 seconds\n",
      "Epoch loss:  0.8204071540385485 \n",
      "\n",
      "-----Training 276-----\n",
      "Elapsed time: 4345.553080320358 seconds\n",
      "Epoch loss:  0.4652099013328552 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 277-----\n",
      "Elapsed time: 4365.023338317871 seconds\n",
      "Epoch loss:  0.5103423856198788 \n",
      "\n",
      "-----Training 278-----\n",
      "Elapsed time: 4379.327017784119 seconds\n",
      "Epoch loss:  0.4005242148414254 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 279-----\n",
      "Elapsed time: 4393.157836198807 seconds\n",
      "Epoch loss:  0.5661041848361492 \n",
      "\n",
      "-----Training 280-----\n",
      "Elapsed time: 4416.446593046188 seconds\n",
      "Epoch loss:  1.9731348231434822 \n",
      "\n",
      "-----Training 281-----\n",
      "Elapsed time: 4429.985962867737 seconds\n",
      "Epoch loss:  0.7040239423513412 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 282-----\n",
      "Elapsed time: 4443.935762643814 seconds\n",
      "Epoch loss:  0.5616728104650974 \n",
      "\n",
      "-----Training 283-----\n",
      "Elapsed time: 4458.0441908836365 seconds\n",
      "Epoch loss:  3.7749546617269516 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 284-----\n",
      "Elapsed time: 4472.536259174347 seconds\n",
      "Epoch loss:  0.43906555976718664 \n",
      "\n",
      "-----Training 285-----\n",
      "Elapsed time: 4487.470289230347 seconds\n",
      "Epoch loss:  0.4728380311280489 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 286-----\n",
      "Elapsed time: 4502.647034168243 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch loss:  2.0913328286260366 \n",
      "\n",
      "-----Training 287-----\n",
      "Elapsed time: 4517.530457496643 seconds\n",
      "Epoch loss:  0.4974133037030697 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 288-----\n",
      "Elapsed time: 4531.7041602134705 seconds\n",
      "Epoch loss:  0.8321628719568253 \n",
      "\n",
      "-----Training 289-----\n",
      "Elapsed time: 4554.779462337494 seconds\n",
      "Epoch loss:  0.5256023611873388 \n",
      "\n",
      "-----Training 290-----\n",
      "Elapsed time: 4567.703393697739 seconds\n",
      "Epoch loss:  0.35421105846762657 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 291-----\n",
      "Elapsed time: 4581.478141546249 seconds\n",
      "Epoch loss:  0.4876464046537876 \n",
      "\n",
      "-----Training 292-----\n",
      "Elapsed time: 4595.683501005173 seconds\n",
      "Epoch loss:  0.38725952059030533 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 293-----\n",
      "Elapsed time: 4610.243221521378 seconds\n",
      "Epoch loss:  2.0360277350991964 \n",
      "\n",
      "-----Training 294-----\n",
      "Elapsed time: 4629.373631477356 seconds\n",
      "Epoch loss:  0.4459423776715994 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 295-----\n",
      "Elapsed time: 4648.762963056564 seconds\n",
      "Epoch loss:  6.676884233020246 \n",
      "\n",
      "-----Training 296-----\n",
      "Elapsed time: 4662.97199344635 seconds\n",
      "Epoch loss:  0.4117635693401098 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 297-----\n",
      "Elapsed time: 4677.8350620269775 seconds\n",
      "Epoch loss:  0.32758077792823315 \n",
      "\n",
      "-----Training 298-----\n",
      "Elapsed time: 4707.601373434067 seconds\n",
      "Epoch loss:  0.7711266819387674 \n",
      "\n",
      "-----Training 299-----\n",
      "Elapsed time: 4721.4343428611755 seconds\n",
      "Epoch loss:  2.002709824591875 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 300-----\n",
      "Elapsed time: 4738.9897108078 seconds\n",
      "Epoch loss:  0.4423819426447153 \n",
      "\n",
      "-----Training 301-----\n",
      "Elapsed time: 4757.697684764862 seconds\n",
      "Epoch loss:  0.44722623750567436 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 302-----\n",
      "Elapsed time: 4774.81800031662 seconds\n",
      "Epoch loss:  0.5616935566067696 \n",
      "\n",
      "-----Training 303-----\n",
      "Elapsed time: 4797.455415725708 seconds\n",
      "Epoch loss:  0.7439287025481462 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 304-----\n",
      "Elapsed time: 4822.228715181351 seconds\n",
      "Epoch loss:  2.1031163949519396 \n",
      "\n",
      "-----Training 305-----\n",
      "Elapsed time: 4834.687923669815 seconds\n",
      "Epoch loss:  0.5125633012503386 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 306-----\n",
      "Elapsed time: 4847.423612356186 seconds\n",
      "Epoch loss:  2.1381041556596756 \n",
      "\n",
      "-----Training 307-----\n",
      "Elapsed time: 4866.913543462753 seconds\n",
      "Epoch loss:  8.476004775613546 \n",
      "\n",
      "-----Training 308-----\n",
      "Elapsed time: 4878.592972278595 seconds\n",
      "Epoch loss:  29.473153915256262 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 309-----\n",
      "Elapsed time: 4890.151389837265 seconds\n",
      "Epoch loss:  26.275652365759015 \n",
      "\n",
      "-----Training 310-----\n",
      "Elapsed time: 4902.02080488205 seconds\n",
      "Epoch loss:  40.81328961625695 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 311-----\n",
      "Elapsed time: 4916.565204620361 seconds\n",
      "Epoch loss:  2.0430030543357134 \n",
      "\n",
      "-----Training 312-----\n",
      "Elapsed time: 4931.6535820961 seconds\n",
      "Epoch loss:  0.8768126349896193 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 313-----\n",
      "Elapsed time: 4948.02565574646 seconds\n",
      "Epoch loss:  0.3807486928999424 \n",
      "\n",
      "-----Training 314-----\n",
      "Elapsed time: 4962.55273771286 seconds\n",
      "Epoch loss:  2.138318184763193 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 315-----\n",
      "Elapsed time: 4976.918334007263 seconds\n",
      "Epoch loss:  3.6069132927805185 \n",
      "\n",
      "-----Training 316-----\n",
      "Elapsed time: 4999.934866428375 seconds\n",
      "Epoch loss:  0.5554596520960331 \n",
      "\n",
      "-----Training 317-----\n",
      "Elapsed time: 5013.861499547958 seconds\n",
      "Epoch loss:  2.561299216002226 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 318-----\n",
      "Elapsed time: 5027.82855796814 seconds\n",
      "Epoch loss:  3.551376672461629 \n",
      "\n",
      "-----Training 319-----\n",
      "Elapsed time: 5042.16656088829 seconds\n",
      "Epoch loss:  2.194133061915636 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 320-----\n",
      "Elapsed time: 5056.544985771179 seconds\n",
      "Epoch loss:  3.824958633631468 \n",
      "\n",
      "-----Training 321-----\n",
      "Elapsed time: 5071.5847153663635 seconds\n",
      "Epoch loss:  0.5135127082467079 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 322-----\n",
      "Elapsed time: 5090.110514640808 seconds\n",
      "Epoch loss:  2.8040827102959156 \n",
      "\n",
      "-----Training 323-----\n",
      "Elapsed time: 5109.238017082214 seconds\n",
      "Epoch loss:  0.6495799999684095 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 324-----\n",
      "Elapsed time: 5128.90118432045 seconds\n",
      "Epoch loss:  2.097893912345171 \n",
      "\n",
      "------Epsilon decays after 2524.838147163391 seconds since last decay-----\n",
      "\n",
      "old epsilon: 0.9 \n",
      "\n",
      "new epsilon: 0.81\n",
      "\n",
      "-----Training 325-----\n",
      "Elapsed time: 5157.300065755844 seconds\n",
      "Epoch loss:  0.3513725660741329 \n",
      "\n",
      "-----Training 326-----\n",
      "Elapsed time: 5174.764382362366 seconds\n",
      "Epoch loss:  0.33352920040488243 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 327-----\n",
      "Elapsed time: 5191.094907999039 seconds\n",
      "Epoch loss:  0.3971851635724306 \n",
      "\n",
      "-----Training 328-----\n",
      "Elapsed time: 5209.906918764114 seconds\n",
      "Epoch loss:  0.5812689587473869 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 329-----\n",
      "Elapsed time: 5229.91698884964 seconds\n",
      "Epoch loss:  0.35859777592122555 \n",
      "\n",
      "-----Training 330-----\n",
      "Elapsed time: 5246.855448484421 seconds\n",
      "Epoch loss:  0.5165059836581349 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 331-----\n",
      "Elapsed time: 5263.973104715347 seconds\n",
      "Epoch loss:  0.5974512714892626 \n",
      "\n",
      "-----Training 332-----\n",
      "Elapsed time: 5279.689631700516 seconds\n",
      "Epoch loss:  0.5114798918366432 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 333-----\n",
      "Elapsed time: 5294.101060152054 seconds\n",
      "Epoch loss:  0.361177533864975 \n",
      "\n",
      "-----Training 334-----\n",
      "Elapsed time: 5317.633076906204 seconds\n",
      "Epoch loss:  0.6187925450503826 \n",
      "\n",
      "-----Training 335-----\n",
      "Elapsed time: 5330.894106626511 seconds\n",
      "Epoch loss:  2.214462239295244 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 336-----\n",
      "Elapsed time: 5344.51934671402 seconds\n",
      "Epoch loss:  1.9999816473573446 \n",
      "\n",
      "-----Training 337-----\n",
      "Elapsed time: 5358.733434438705 seconds\n",
      "Epoch loss:  2.105829618871212 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 338-----\n",
      "Elapsed time: 5373.5801639556885 seconds\n",
      "Epoch loss:  2.09902011975646 \n",
      "\n",
      "-----Training 339-----\n",
      "Elapsed time: 5388.967695474625 seconds\n",
      "Epoch loss:  0.4993163626641035 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 340-----\n",
      "Elapsed time: 5403.908323526382 seconds\n",
      "Epoch loss:  0.4227646104991436 \n",
      "\n",
      "-----Training 341-----\n",
      "Elapsed time: 5418.444568872452 seconds\n",
      "Epoch loss:  0.4507887866348028 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 342-----\n",
      "Elapsed time: 5432.498183012009 seconds\n",
      "Epoch loss:  0.7783984802663326 \n",
      "\n",
      "-----Training 343-----\n",
      "Elapsed time: 5455.955707788467 seconds\n",
      "Epoch loss:  0.6876028254628181 \n",
      "\n",
      "-----Training 344-----\n",
      "Elapsed time: 5468.896465539932 seconds\n",
      "Epoch loss:  0.45608560740947723 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 345-----\n",
      "Elapsed time: 5482.6144869327545 seconds\n",
      "Epoch loss:  0.4688855018466711 \n",
      "\n",
      "-----Training 346-----\n",
      "Elapsed time: 5496.861477136612 seconds\n",
      "Epoch loss:  0.8831352349370718 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 347-----\n",
      "Elapsed time: 5511.747071266174 seconds\n",
      "Epoch loss:  0.47919720970094204 \n",
      "\n",
      "-----Training 348-----\n",
      "Elapsed time: 5527.547368049622 seconds\n",
      "Epoch loss:  0.3981565125286579 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 349-----\n",
      "Elapsed time: 5542.684371471405 seconds\n",
      "Epoch loss:  0.41013224236667156 \n",
      "\n",
      "-----Training 350-----\n",
      "Elapsed time: 5557.0413336753845 seconds\n",
      "Epoch loss:  0.5169714819639921 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 351-----\n",
      "Elapsed time: 5570.910810709 seconds\n",
      "Epoch loss:  0.6603306047618389 \n",
      "\n",
      "-----Training 352-----\n",
      "Elapsed time: 5595.138204097748 seconds\n",
      "Epoch loss:  0.4498147573322058 \n",
      "\n",
      "-----Training 353-----\n",
      "Elapsed time: 5610.1770696640015 seconds\n",
      "Epoch loss:  0.4956091567873955 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 354-----\n",
      "Elapsed time: 5624.044635772705 seconds\n",
      "Epoch loss:  0.41089736111462116 \n",
      "\n",
      "-----Training 355-----\n",
      "Elapsed time: 5638.415287971497 seconds\n",
      "Epoch loss:  6.889627650380135 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 356-----\n",
      "Elapsed time: 5653.0692486763 seconds\n",
      "Epoch loss:  0.5639779604971409 \n",
      "\n",
      "-----Training 357-----\n",
      "Elapsed time: 5668.0422377586365 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch loss:  8.781989444047213 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 358-----\n",
      "Elapsed time: 5683.489421367645 seconds\n",
      "Epoch loss:  0.4977096654474735 \n",
      "\n",
      "-----Training 359-----\n",
      "Elapsed time: 5698.59854221344 seconds\n",
      "Epoch loss:  2.0279298070818186 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 360-----\n",
      "Elapsed time: 5712.675486087799 seconds\n",
      "Epoch loss:  0.671045670285821 \n",
      "\n",
      "-----Training 361-----\n",
      "Elapsed time: 5735.789103031158 seconds\n",
      "Epoch loss:  0.415198739618063 \n",
      "\n",
      "-----Training 362-----\n",
      "Elapsed time: 5750.124744653702 seconds\n",
      "Epoch loss:  1.9616805035620928 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 363-----\n",
      "Elapsed time: 5764.484836816788 seconds\n",
      "Epoch loss:  2.2300633154809475 \n",
      "\n",
      "-----Training 364-----\n",
      "Elapsed time: 5778.72723031044 seconds\n",
      "Epoch loss:  0.4077579565346241 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 365-----\n",
      "Elapsed time: 5793.4119255542755 seconds\n",
      "Epoch loss:  0.504300570115447 \n",
      "\n",
      "-----Training 366-----\n",
      "Elapsed time: 5809.800873994827 seconds\n",
      "Epoch loss:  0.5634359382092953 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 367-----\n",
      "Elapsed time: 5826.488874435425 seconds\n",
      "Epoch loss:  0.4625225495547056 \n",
      "\n",
      "-----Training 368-----\n",
      "Elapsed time: 5842.258967876434 seconds\n",
      "Epoch loss:  0.5482011400163174 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 369-----\n",
      "Elapsed time: 5856.842972755432 seconds\n",
      "Epoch loss:  0.640781182795763 \n",
      "\n",
      "-----Training 370-----\n",
      "Elapsed time: 5882.634028434753 seconds\n",
      "Epoch loss:  2.1166049763560295 \n",
      "\n",
      "-----Training 371-----\n",
      "Elapsed time: 5903.4895079135895 seconds\n",
      "Epoch loss:  0.41478169336915016 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 372-----\n",
      "Elapsed time: 5920.62372136116 seconds\n",
      "Epoch loss:  2.261501055210829 \n",
      "\n",
      "-----Training 373-----\n",
      "Elapsed time: 5938.268502950668 seconds\n",
      "Epoch loss:  0.6395364925265312 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 374-----\n",
      "Elapsed time: 5953.241536140442 seconds\n",
      "Epoch loss:  0.5602584611624479 \n",
      "\n",
      "-----Training 375-----\n",
      "Elapsed time: 5970.05367398262 seconds\n",
      "Epoch loss:  2.0360301062464714 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 376-----\n",
      "Elapsed time: 5985.991148233414 seconds\n",
      "Epoch loss:  1.8906146697700024 \n",
      "\n",
      "-----Training 377-----\n",
      "Elapsed time: 6000.534415721893 seconds\n",
      "Epoch loss:  0.5835932642221451 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 378-----\n",
      "Elapsed time: 6014.6321477890015 seconds\n",
      "Epoch loss:  0.5266642607748508 \n",
      "\n",
      "-----Training 379-----\n",
      "Elapsed time: 6037.386505842209 seconds\n",
      "Epoch loss:  0.5298772174865007 \n",
      "\n",
      "-----Training 380-----\n",
      "Elapsed time: 6051.028352022171 seconds\n",
      "Epoch loss:  0.5035778284072876 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 381-----\n",
      "Elapsed time: 6065.378331422806 seconds\n",
      "Epoch loss:  0.4543945640325546 \n",
      "\n",
      "-----Training 382-----\n",
      "Elapsed time: 6079.434915065765 seconds\n",
      "Epoch loss:  0.6256381720304489 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 383-----\n",
      "Elapsed time: 6093.990745306015 seconds\n",
      "Epoch loss:  1.911631092429161 \n",
      "\n",
      "-----Training 384-----\n",
      "Elapsed time: 6109.579186201096 seconds\n",
      "Epoch loss:  0.5682920925319195 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 385-----\n",
      "Elapsed time: 6124.881452083588 seconds\n",
      "Epoch loss:  2.0511577036231756 \n",
      "\n",
      "-----Training 386-----\n",
      "Elapsed time: 6139.430869817734 seconds\n",
      "Epoch loss:  0.5314921885728836 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 387-----\n",
      "Elapsed time: 6153.949114561081 seconds\n",
      "Epoch loss:  0.5237730853259563 \n",
      "\n",
      "-----Training 388-----\n",
      "Elapsed time: 6178.851588487625 seconds\n",
      "Epoch loss:  0.515411015599966 \n",
      "\n",
      "-----Training 389-----\n",
      "Elapsed time: 6193.675572156906 seconds\n",
      "Epoch loss:  0.5337578784674406 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 390-----\n",
      "Elapsed time: 6207.79495215416 seconds\n",
      "Epoch loss:  0.5274832155555487 \n",
      "\n",
      "-----Training 391-----\n",
      "Elapsed time: 6223.62312579155 seconds\n",
      "Epoch loss:  0.4216821137815714 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 392-----\n",
      "Elapsed time: 6239.937871217728 seconds\n",
      "Epoch loss:  0.6248564012348652 \n",
      "\n",
      "-----Training 393-----\n",
      "Elapsed time: 6255.995847225189 seconds\n",
      "Epoch loss:  0.4401975655928254 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 394-----\n",
      "Elapsed time: 6275.949110746384 seconds\n",
      "Epoch loss:  0.45842089504003525 \n",
      "\n",
      "-----Training 395-----\n",
      "Elapsed time: 6293.859177350998 seconds\n",
      "Epoch loss:  0.6696699392050505 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 396-----\n",
      "Elapsed time: 6310.384428024292 seconds\n",
      "Epoch loss:  0.6952340845018625 \n",
      "\n",
      "-----Training 397-----\n",
      "Elapsed time: 6333.179493904114 seconds\n",
      "Epoch loss:  0.8342935033142567 \n",
      "\n",
      "-----Training 398-----\n",
      "Elapsed time: 6347.313684225082 seconds\n",
      "Epoch loss:  0.44319416396319866 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 399-----\n",
      "Elapsed time: 6361.218901634216 seconds\n",
      "Epoch loss:  0.39909856393933296 \n",
      "\n",
      "-----Training 400-----\n",
      "Elapsed time: 6375.352275133133 seconds\n",
      "Epoch loss:  0.3819848746061325 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 401-----\n",
      "Elapsed time: 6392.484763383865 seconds\n",
      "Epoch loss:  2.2530298605561256 \n",
      "\n",
      "-----Training 402-----\n",
      "Elapsed time: 6406.526467323303 seconds\n",
      "Epoch loss:  0.5795588903129101 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 403-----\n",
      "Elapsed time: 6431.7169597148895 seconds\n",
      "Epoch loss:  0.4164896123111248 \n",
      "\n",
      "-----Training 404-----\n",
      "Elapsed time: 6452.455827474594 seconds\n",
      "Epoch loss:  0.6723603494465351 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 405-----\n",
      "Elapsed time: 6472.046735048294 seconds\n",
      "Epoch loss:  2.4040010534226894 \n",
      "\n",
      "-----Training 406-----\n",
      "Elapsed time: 6501.096191644669 seconds\n",
      "Epoch loss:  0.6066330634057522 \n",
      "\n",
      "-----Training 407-----\n",
      "Elapsed time: 6515.601094722748 seconds\n",
      "Epoch loss:  0.6090770848095417 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 408-----\n",
      "Elapsed time: 6529.677492141724 seconds\n",
      "Epoch loss:  0.5671512074768543 \n",
      "\n",
      "-----Training 409-----\n",
      "Elapsed time: 6544.569096088409 seconds\n",
      "Epoch loss:  0.5812062099575996 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 410-----\n",
      "Elapsed time: 6560.668508529663 seconds\n",
      "Epoch loss:  0.5665435884147882 \n",
      "\n",
      "-----Training 411-----\n",
      "Elapsed time: 6576.207940816879 seconds\n",
      "Epoch loss:  0.6976273022592068 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 412-----\n",
      "Elapsed time: 6592.211444377899 seconds\n",
      "Epoch loss:  0.5016072299331427 \n",
      "\n",
      "-----Training 413-----\n",
      "Elapsed time: 6607.817260026932 seconds\n",
      "Epoch loss:  0.4201303720474243 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 414-----\n",
      "Elapsed time: 6621.96101641655 seconds\n",
      "Epoch loss:  0.5710708647966385 \n",
      "\n",
      "-----Training 415-----\n",
      "Elapsed time: 6646.162174463272 seconds\n",
      "Epoch loss:  0.4279622323811054 \n",
      "\n",
      "-----Training 416-----\n",
      "Elapsed time: 6658.673780441284 seconds\n",
      "Epoch loss:  0.5046326648443937 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 417-----\n",
      "Elapsed time: 6672.779326677322 seconds\n",
      "Epoch loss:  0.46809775568544865 \n",
      "\n",
      "-----Training 418-----\n",
      "Elapsed time: 6687.447559833527 seconds\n",
      "Epoch loss:  0.5313639603555202 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 419-----\n",
      "Elapsed time: 6703.027508497238 seconds\n",
      "Epoch loss:  0.6232210602611303 \n",
      "\n",
      "-----Training 420-----\n",
      "Elapsed time: 6718.190560340881 seconds\n",
      "Epoch loss:  0.41464968398213387 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 421-----\n",
      "Elapsed time: 6734.480221033096 seconds\n",
      "Epoch loss:  0.7349999118596315 \n",
      "\n",
      "-----Training 422-----\n",
      "Elapsed time: 6756.159598350525 seconds\n",
      "Epoch loss:  0.6601238548755646 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 423-----\n",
      "Elapsed time: 6773.922445058823 seconds\n",
      "Epoch loss:  0.4935398269444704 \n",
      "\n",
      "-----Training 424-----\n",
      "Elapsed time: 6798.425116062164 seconds\n",
      "Epoch loss:  0.40206069219857454 \n",
      "\n",
      "-----Training 425-----\n",
      "Elapsed time: 6812.254091978073 seconds\n",
      "Epoch loss:  0.4445514492690563 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 426-----\n",
      "Elapsed time: 6826.365009069443 seconds\n",
      "Epoch loss:  0.44742878153920174 \n",
      "\n",
      "-----Training 427-----\n",
      "Elapsed time: 6843.430382490158 seconds\n",
      "Epoch loss:  0.4790287557989359 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 428-----\n",
      "Elapsed time: 6859.177662849426 seconds\n",
      "Epoch loss:  0.5139061016961932 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Training 429-----\n",
      "Elapsed time: 6876.6677803993225 seconds\n",
      "Epoch loss:  0.3931716438382864 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 430-----\n",
      "Elapsed time: 6892.673176527023 seconds\n",
      "Epoch loss:  0.44822588190436363 \n",
      "\n",
      "-----Training 431-----\n",
      "Elapsed time: 6908.800713777542 seconds\n",
      "Epoch loss:  0.3853431399911642 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 432-----\n",
      "Elapsed time: 6925.210090398788 seconds\n",
      "Epoch loss:  0.41053406335413456 \n",
      "\n",
      "-----Training 433-----\n",
      "Elapsed time: 6949.348644018173 seconds\n",
      "Epoch loss:  0.3922902047634125 \n",
      "\n",
      "-----Training 434-----\n",
      "Elapsed time: 6963.079214334488 seconds\n",
      "Epoch loss:  0.31693282909691334 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 435-----\n",
      "Elapsed time: 6977.467838048935 seconds\n",
      "Epoch loss:  0.3135170489549637 \n",
      "\n",
      "-----Training 436-----\n",
      "Elapsed time: 6992.361857414246 seconds\n",
      "Epoch loss:  0.45154211670160294 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 437-----\n",
      "Elapsed time: 7008.482721567154 seconds\n",
      "Epoch loss:  0.48751782812178135 \n",
      "\n",
      "-----Training 438-----\n",
      "Elapsed time: 7025.813394784927 seconds\n",
      "Epoch loss:  0.451361695304513 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 439-----\n",
      "Elapsed time: 7043.9417181015015 seconds\n",
      "Epoch loss:  0.3425724934786558 \n",
      "\n",
      "-----Training 440-----\n",
      "Elapsed time: 7060.0317595005035 seconds\n",
      "Epoch loss:  0.7480169646441936 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 441-----\n",
      "Elapsed time: 7074.759556293488 seconds\n",
      "Epoch loss:  0.3665610998868942 \n",
      "\n",
      "-----Training 442-----\n",
      "Elapsed time: 7100.334545612335 seconds\n",
      "Epoch loss:  0.4118504375219345 \n",
      "\n",
      "-----Training 443-----\n",
      "Elapsed time: 7115.360355615616 seconds\n",
      "Epoch loss:  0.43629312235862017 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 444-----\n",
      "Elapsed time: 7129.9539041519165 seconds\n",
      "Epoch loss:  2.391585363075137 \n",
      "\n",
      "-----Training 445-----\n",
      "Elapsed time: 7144.161119937897 seconds\n",
      "Epoch loss:  0.3922345992177725 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 446-----\n",
      "Elapsed time: 7159.210955858231 seconds\n",
      "Epoch loss:  2.3635088559240103 \n",
      "\n",
      "-----Training 447-----\n",
      "Elapsed time: 7174.588817834854 seconds\n",
      "Epoch loss:  0.6042688749730587 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 448-----\n",
      "Elapsed time: 7190.352931261063 seconds\n",
      "Epoch loss:  0.6447649542242289 \n",
      "\n",
      "-----Training 449-----\n",
      "Elapsed time: 7205.053192853928 seconds\n",
      "Epoch loss:  0.6274656914174557 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 450-----\n",
      "Elapsed time: 7219.375138044357 seconds\n",
      "Epoch loss:  2.4922041930258274 \n",
      "\n",
      "-----Training 451-----\n",
      "Elapsed time: 7242.856640815735 seconds\n",
      "Epoch loss:  0.3449611607939005 \n",
      "\n",
      "-----Training 452-----\n",
      "Elapsed time: 7256.456398487091 seconds\n",
      "Epoch loss:  0.44799206778407097 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 453-----\n",
      "Elapsed time: 7270.433244466782 seconds\n",
      "Epoch loss:  6.876450892537832 \n",
      "\n",
      "-----Training 454-----\n",
      "Elapsed time: 7284.90113902092 seconds\n",
      "Epoch loss:  26.11164174415171 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 455-----\n",
      "Elapsed time: 7299.944598674774 seconds\n",
      "Epoch loss:  0.6859207674860954 \n",
      "\n",
      "-----Training 456-----\n",
      "Elapsed time: 7315.45435500145 seconds\n",
      "Epoch loss:  0.39903764985501766 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 457-----\n",
      "Elapsed time: 7330.907963275909 seconds\n",
      "Epoch loss:  0.4388245064765215 \n",
      "\n",
      "-----Training 458-----\n",
      "Elapsed time: 7346.121958494186 seconds\n",
      "Epoch loss:  0.31538633443415165 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 459-----\n",
      "Elapsed time: 7361.529296159744 seconds\n",
      "Epoch loss:  0.462483212351799 \n",
      "\n",
      "-----Training 460-----\n",
      "Elapsed time: 7385.679891586304 seconds\n",
      "Epoch loss:  0.33442359417676926 \n",
      "\n",
      "-----Training 461-----\n",
      "Elapsed time: 7399.08962893486 seconds\n",
      "Epoch loss:  0.3748040469363332 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 462-----\n",
      "Elapsed time: 7413.440082550049 seconds\n",
      "Epoch loss:  0.3860018905252218 \n",
      "\n",
      "-----Training 463-----\n",
      "Elapsed time: 7428.357843160629 seconds\n",
      "Epoch loss:  0.4380450118333101 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 464-----\n",
      "Elapsed time: 7443.397169351578 seconds\n",
      "Epoch loss:  0.38221525959670544 \n",
      "\n",
      "-----Training 465-----\n",
      "Elapsed time: 7458.68762588501 seconds\n",
      "Epoch loss:  0.37299265526235104 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 466-----\n",
      "Elapsed time: 7474.0707631111145 seconds\n",
      "Epoch loss:  0.4195573478937149 \n",
      "\n",
      "-----Training 467-----\n",
      "Elapsed time: 7489.167786359787 seconds\n",
      "Epoch loss:  0.33221581671386957 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 468-----\n",
      "Elapsed time: 7503.541725873947 seconds\n",
      "Epoch loss:  0.4381845649331808 \n",
      "\n",
      "-----Training 469-----\n",
      "Elapsed time: 7526.487439632416 seconds\n",
      "Epoch loss:  0.605056082829833 \n",
      "\n",
      "-----Training 470-----\n",
      "Elapsed time: 7539.725122213364 seconds\n",
      "Epoch loss:  0.34016035962849855 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 471-----\n",
      "Elapsed time: 7554.457241773605 seconds\n",
      "Epoch loss:  2.003495266661048 \n",
      "\n",
      "-----Training 472-----\n",
      "Elapsed time: 7568.92125749588 seconds\n",
      "Epoch loss:  2.251229889690876 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 473-----\n",
      "Elapsed time: 7583.875885248184 seconds\n",
      "Epoch loss:  0.4585736244916916 \n",
      "\n",
      "-----Training 474-----\n",
      "Elapsed time: 7599.332362651825 seconds\n",
      "Epoch loss:  0.49322270043194294 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 475-----\n",
      "Elapsed time: 7614.721143245697 seconds\n",
      "Epoch loss:  0.4483638033270836 \n",
      "\n",
      "-----Training 476-----\n",
      "Elapsed time: 7630.360747098923 seconds\n",
      "Epoch loss:  0.4933082051575184 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 477-----\n",
      "Elapsed time: 7645.154925584793 seconds\n",
      "Epoch loss:  6.8308496586978436 \n",
      "\n",
      "------Epsilon decays after 2514.020232439041 seconds since last decay-----\n",
      "\n",
      "old epsilon: 0.81 \n",
      "\n",
      "new epsilon: 0.7290000000000001\n",
      "\n",
      "-----Training 478-----\n",
      "Elapsed time: 7668.8850910663605 seconds\n",
      "Epoch loss:  0.7211931273341179 \n",
      "\n",
      "-----Training 479-----\n",
      "Elapsed time: 7682.152627229691 seconds\n",
      "Epoch loss:  0.4037995394319296 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 480-----\n",
      "Elapsed time: 7695.768751621246 seconds\n",
      "Epoch loss:  0.43090776540338993 \n",
      "\n",
      "-----Training 481-----\n",
      "Elapsed time: 7709.98619556427 seconds\n",
      "Epoch loss:  0.6025659032166004 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 482-----\n",
      "Elapsed time: 7725.210466384888 seconds\n",
      "Epoch loss:  0.4162749368697405 \n",
      "\n",
      "-----Training 483-----\n",
      "Elapsed time: 7740.421303987503 seconds\n",
      "Epoch loss:  0.4436533246189356 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 484-----\n",
      "Elapsed time: 7756.333800315857 seconds\n",
      "Epoch loss:  0.5799244306981564 \n",
      "\n",
      "-----Training 485-----\n",
      "Elapsed time: 7771.60759305954 seconds\n",
      "Epoch loss:  0.6834769053384662 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 486-----\n",
      "Elapsed time: 7786.080766916275 seconds\n",
      "Epoch loss:  0.4383837413042784 \n",
      "\n",
      "-----Training 487-----\n",
      "Elapsed time: 7809.301905870438 seconds\n",
      "Epoch loss:  2.14580300077796 \n",
      "\n",
      "-----Training 488-----\n",
      "Elapsed time: 7822.658718347549 seconds\n",
      "Epoch loss:  0.6802871450781822 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 489-----\n",
      "Elapsed time: 7836.620016336441 seconds\n",
      "Epoch loss:  0.5065878629684448 \n",
      "\n",
      "-----Training 490-----\n",
      "Elapsed time: 7851.146054267883 seconds\n",
      "Epoch loss:  6.9203877449035645 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 491-----\n",
      "Elapsed time: 7866.123094558716 seconds\n",
      "Epoch loss:  2.1332524064928293 \n",
      "\n",
      "-----Training 492-----\n",
      "Elapsed time: 7881.498883485794 seconds\n",
      "Epoch loss:  0.6538347657769918 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n",
      "-----Training 493-----\n",
      "Elapsed time: 7897.134472131729 seconds\n",
      "Epoch loss:  0.4144863039255142 \n",
      "\n",
      "-----Training 494-----\n",
      "Elapsed time: 7912.891558647156 seconds\n",
      "Epoch loss:  0.6494412925094366 \n",
      "\n",
      "-----Copying pred_NN to target_NN-----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#initialize environment\n",
    "env = gym.make(\"ALE/Pacman-v5\",render_mode=\"rgb_array\")\n",
    "#preprocess environment\n",
    "env = gym.wrappers.AtariPreprocessing(env, screen_size=84, grayscale_obs=True, frame_skip=1, noop_max=30, scale_obs = True)\n",
    "#start environment\n",
    "state, info = env.reset()\n",
    "\n",
    "#hyperparams\n",
    "epsilon = 1\n",
    "epsilon_decay = 0.9\n",
    "gamma = 0.75\n",
    "experience_capacity = 10000\n",
    "training_freq = 1000\n",
    "copying_freq = 2000\n",
    "samples_per_training_session = 500\n",
    "samples_per_batch = 50\n",
    "\n",
    "#initialize agent\n",
    "agent = DQN_agent()\n",
    "agent.pred_NN.train(mode=False)\n",
    "agent.target_NN.train(mode=False)\n",
    "\n",
    "#load saved model to agent NNs\n",
    "#agent.pred_NN.load_state_dict(torch.load(\"model\"))\n",
    "#agent.target_NN = copy.deepcopy(agent.pred_NN)\n",
    "\n",
    "#select first action\n",
    "action = random.randint(0, 4)\n",
    "\n",
    "#get first states\n",
    "state1, reward, terminated, truncated, info = env.step(action)\n",
    "state2, reward, terminated, truncated, info = env.step(action)\n",
    "state3, reward, terminated, truncated, info = env.step(action)\n",
    "state4, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "#convert first states to correct datatype and stack\n",
    "state1 = TF.to_tensor(state1)     \n",
    "state2 = TF.to_tensor(state2)\n",
    "state3 = TF.to_tensor(state3)\n",
    "state4 = TF.to_tensor(state4)\n",
    "state_stack = torch.cat((state1,state2,state3,state4))\n",
    "state_stack = torch.unsqueeze(state_stack, 0)\n",
    "\n",
    "#plot image, to se resolution\n",
    "#img = state4.permute(1, 2, 0).numpy()\n",
    "#plt.imshow(img)\n",
    "#plt.show()\n",
    "\n",
    "print('Plot filters in first layer\\n')\n",
    "kernels = agent.pred_NN.stack[0].weight.detach().clone()\n",
    "kernels = kernels - kernels.min()\n",
    "kernels = kernels / kernels.max()\n",
    "filter_img = torchvision.utils.make_grid(kernels, nrow = 8)\n",
    "plt.imshow(filter_img.permute(1, 2, 0))\n",
    "plt.show() \n",
    "\n",
    "#timer and variables connected to time\n",
    "start_time = time.time()\n",
    "epsilon_start_time = time.time()\n",
    "elapsed_time = 0\n",
    "max_time = 40000\n",
    "training_time = 0\n",
    "decay_freq = max_time/16\n",
    "\n",
    "#for logging\n",
    "training_session = 0\n",
    "\n",
    "#loops until max_time is reached\n",
    "while elapsed_time < max_time:\n",
    "    experiences = []\n",
    "    \n",
    "    #loops until experience_capacity is reached\n",
    "    for i in range(1, experience_capacity):\n",
    "        \n",
    "    \n",
    "        #predict q-values and choose action\n",
    "        pred = agent.predict(state_stack)\n",
    "        pred = pred.squeeze()\n",
    "        action = agent.action(pred)\n",
    "        \n",
    "        #get next states\n",
    "        next_state1, reward1, terminated, truncated, info = env.step(action)\n",
    "        next_state2, reward2, terminated, truncated, info = env.step(action)\n",
    "        next_state3, reward3, terminated, truncated, info = env.step(action)\n",
    "        next_state4, reward4, terminated, truncated, info = env.step(action)\n",
    "\n",
    "        #if pac-man dies 4 times, reset and start again\n",
    "        if terminated or truncated: \n",
    "            #restart pacman\n",
    "            env.reset()\n",
    "            #select first action\n",
    "            action = random.randint(0, 4)\n",
    "            #get first states\n",
    "            next_state1, reward1, terminated, truncated, info = env.step(action)\n",
    "            next_state2, reward2, terminated, truncated, info = env.step(action)\n",
    "            next_state3, reward3, terminated, truncated, info = env.step(action)\n",
    "            next_state4, reward4, terminated, truncated, info = env.step(action)\n",
    "            \n",
    "        #convert next state to correct type and stack\n",
    "        next_state1 = TF.to_tensor(next_state1)\n",
    "        next_state2 = TF.to_tensor(next_state2)\n",
    "        next_state3 = TF.to_tensor(next_state3)\n",
    "        next_state4 = TF.to_tensor(next_state4)\n",
    "        next_state_stack = torch.cat((next_state1,next_state2,next_state3,next_state4)) \n",
    "        next_state_stack = torch.unsqueeze(next_state_stack, 0)\n",
    "        \n",
    "        #sum rewards \n",
    "        tot_reward = 0\n",
    "        tot_reward = reward1 + reward2 + reward3 + reward4\n",
    "        \n",
    "        #add to experiences\n",
    "        save_this = [state_stack, action, tot_reward, next_state_stack] \n",
    "        experiences.append(save_this)\n",
    "        \n",
    "        #train\n",
    "        if i % training_freq == 0:\n",
    "            training_session += 1\n",
    "            print(f'-----Training {training_session}-----')\n",
    "            elapsed_time = time.time() - start_time\n",
    "            print(f'Elapsed time: {elapsed_time} seconds')\n",
    "            experiences_train = random.choices(experiences, k=samples_per_training_session)\n",
    "            epoch_loss = agent.train(experiences_train)\n",
    "            print(\"Epoch loss: \", epoch_loss, \"\\n\")  \n",
    "            \n",
    "        #copy\n",
    "        if i % copying_freq == 0:\n",
    "            print('-----Copying pred_NN to target_NN-----\\n')\n",
    "            agent.copy()\n",
    "            elapsed_time = time.time() - start_time\n",
    "            if elapsed_time > max_time:\n",
    "                break\n",
    "                \n",
    "        #next state stack becomes current state stack\n",
    "        state_stack = next_state_stack\n",
    "            \n",
    "        \n",
    "    #decay epsilon\n",
    "    if(epsilon > 0.2 and (time.time() - epsilon_start_time) > decay_freq):\n",
    "        print(f'------Epsilon decays after {(time.time() - epsilon_start_time)} seconds since last decay-----\\n')\n",
    "        print(f'old epsilon: {epsilon} \\n')\n",
    "        epsilon = epsilon * epsilon_decay \n",
    "        print(f'new epsilon: {epsilon}\\n')\n",
    "        epsilon_start_time = time.time()\n",
    "        \n",
    "\n",
    "print(f'*****stopped training after {elapsed_time} seconds*****\\n')\n",
    "\n",
    "print('*****Plot filters in first layer*****\\n')\n",
    "kernels = agent.pred_NN.stack[0].weight.detach().clone()\n",
    "kernels = kernels - kernels.min()\n",
    "kernels = kernels / kernels.max()\n",
    "filter_img = torchvision.utils.make_grid(kernels, nrow = 8)\n",
    "plt.imshow(filter_img.permute(1, 2, 0))\n",
    "plt.show() \n",
    "\n",
    "print('*****Pickle Dumping model*****\\n')\n",
    "\n",
    "file = open('safetyPickleDump', 'wb')\n",
    "pickle.dump(agent, file)\n",
    "file.close()\n",
    "\n",
    "print(\"*****Saving model*****\")\n",
    "torch.save(agent.pred_NN.state_dict(), \"model\")\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f008d8b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4d1cca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d4bd0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7746d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
