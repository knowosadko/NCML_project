{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12eac9e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gymnasium in ./rlenv/lib/python3.10/site-packages (0.28.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in ./rlenv/lib/python3.10/site-packages (from gymnasium) (1.24.3)\n",
      "Requirement already satisfied: jax-jumpy>=1.0.0 in ./rlenv/lib/python3.10/site-packages (from gymnasium) (1.0.0)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in ./rlenv/lib/python3.10/site-packages (from gymnasium) (2.2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in ./rlenv/lib/python3.10/site-packages (from gymnasium) (4.6.2)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in ./rlenv/lib/python3.10/site-packages (from gymnasium) (0.0.4)\n",
      "Requirement already satisfied: gymnasium[accept-rom-license,atari] in ./rlenv/lib/python3.10/site-packages (0.28.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in ./rlenv/lib/python3.10/site-packages (from gymnasium[accept-rom-license,atari]) (1.24.3)\n",
      "Requirement already satisfied: jax-jumpy>=1.0.0 in ./rlenv/lib/python3.10/site-packages (from gymnasium[accept-rom-license,atari]) (1.0.0)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in ./rlenv/lib/python3.10/site-packages (from gymnasium[accept-rom-license,atari]) (2.2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in ./rlenv/lib/python3.10/site-packages (from gymnasium[accept-rom-license,atari]) (4.6.2)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in ./rlenv/lib/python3.10/site-packages (from gymnasium[accept-rom-license,atari]) (0.0.4)\n",
      "Requirement already satisfied: shimmy[atari]<1.0,>=0.1.0 in ./rlenv/lib/python3.10/site-packages (from gymnasium[accept-rom-license,atari]) (0.2.1)\n",
      "Requirement already satisfied: autorom[accept-rom-license]~=0.4.2 in ./rlenv/lib/python3.10/site-packages (from gymnasium[accept-rom-license,atari]) (0.4.2)\n",
      "Requirement already satisfied: click in ./rlenv/lib/python3.10/site-packages (from autorom[accept-rom-license]~=0.4.2->gymnasium[accept-rom-license,atari]) (8.1.3)\n",
      "Requirement already satisfied: requests in ./rlenv/lib/python3.10/site-packages (from autorom[accept-rom-license]~=0.4.2->gymnasium[accept-rom-license,atari]) (2.31.0)\n",
      "Requirement already satisfied: tqdm in ./rlenv/lib/python3.10/site-packages (from autorom[accept-rom-license]~=0.4.2->gymnasium[accept-rom-license,atari]) (4.65.0)\n",
      "Requirement already satisfied: AutoROM.accept-rom-license in ./rlenv/lib/python3.10/site-packages (from autorom[accept-rom-license]~=0.4.2->gymnasium[accept-rom-license,atari]) (0.6.1)\n",
      "Requirement already satisfied: ale-py~=0.8.1 in ./rlenv/lib/python3.10/site-packages (from shimmy[atari]<1.0,>=0.1.0->gymnasium[accept-rom-license,atari]) (0.8.1)\n",
      "Requirement already satisfied: importlib-resources in ./rlenv/lib/python3.10/site-packages (from ale-py~=0.8.1->shimmy[atari]<1.0,>=0.1.0->gymnasium[accept-rom-license,atari]) (5.12.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./rlenv/lib/python3.10/site-packages (from requests->autorom[accept-rom-license]~=0.4.2->gymnasium[accept-rom-license,atari]) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./rlenv/lib/python3.10/site-packages (from requests->autorom[accept-rom-license]~=0.4.2->gymnasium[accept-rom-license,atari]) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./rlenv/lib/python3.10/site-packages (from requests->autorom[accept-rom-license]~=0.4.2->gymnasium[accept-rom-license,atari]) (2.0.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./rlenv/lib/python3.10/site-packages (from requests->autorom[accept-rom-license]~=0.4.2->gymnasium[accept-rom-license,atari]) (2023.5.7)\n",
      "Requirement already satisfied: torch in ./rlenv/lib/python3.10/site-packages (2.0.1)\n",
      "Requirement already satisfied: filelock in ./rlenv/lib/python3.10/site-packages (from torch) (3.12.0)\n",
      "Requirement already satisfied: typing-extensions in ./rlenv/lib/python3.10/site-packages (from torch) (4.6.2)\n",
      "Requirement already satisfied: sympy in ./rlenv/lib/python3.10/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in ./rlenv/lib/python3.10/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in ./rlenv/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in ./rlenv/lib/python3.10/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in ./rlenv/lib/python3.10/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in ./rlenv/lib/python3.10/site-packages (from torch) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in ./rlenv/lib/python3.10/site-packages (from torch) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in ./rlenv/lib/python3.10/site-packages (from torch) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in ./rlenv/lib/python3.10/site-packages (from torch) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in ./rlenv/lib/python3.10/site-packages (from torch) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in ./rlenv/lib/python3.10/site-packages (from torch) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in ./rlenv/lib/python3.10/site-packages (from torch) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in ./rlenv/lib/python3.10/site-packages (from torch) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in ./rlenv/lib/python3.10/site-packages (from torch) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in ./rlenv/lib/python3.10/site-packages (from torch) (2.0.0)\n",
      "Requirement already satisfied: setuptools in ./rlenv/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (65.4.0)\n",
      "Requirement already satisfied: wheel in ./rlenv/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.37.1)\n",
      "Requirement already satisfied: cmake in ./rlenv/lib/python3.10/site-packages (from triton==2.0.0->torch) (3.26.3)\n",
      "Requirement already satisfied: lit in ./rlenv/lib/python3.10/site-packages (from triton==2.0.0->torch) (16.0.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./rlenv/lib/python3.10/site-packages (from jinja2->torch) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./rlenv/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: torchvision in ./rlenv/lib/python3.10/site-packages (0.15.2)\n",
      "Requirement already satisfied: numpy in ./rlenv/lib/python3.10/site-packages (from torchvision) (1.24.3)\n",
      "Requirement already satisfied: requests in ./rlenv/lib/python3.10/site-packages (from torchvision) (2.31.0)\n",
      "Requirement already satisfied: torch==2.0.1 in ./rlenv/lib/python3.10/site-packages (from torchvision) (2.0.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./rlenv/lib/python3.10/site-packages (from torchvision) (9.5.0)\n",
      "Requirement already satisfied: filelock in ./rlenv/lib/python3.10/site-packages (from torch==2.0.1->torchvision) (3.12.0)\n",
      "Requirement already satisfied: typing-extensions in ./rlenv/lib/python3.10/site-packages (from torch==2.0.1->torchvision) (4.6.2)\n",
      "Requirement already satisfied: sympy in ./rlenv/lib/python3.10/site-packages (from torch==2.0.1->torchvision) (1.12)\n",
      "Requirement already satisfied: networkx in ./rlenv/lib/python3.10/site-packages (from torch==2.0.1->torchvision) (3.1)\n",
      "Requirement already satisfied: jinja2 in ./rlenv/lib/python3.10/site-packages (from torch==2.0.1->torchvision) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in ./rlenv/lib/python3.10/site-packages (from torch==2.0.1->torchvision) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in ./rlenv/lib/python3.10/site-packages (from torch==2.0.1->torchvision) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in ./rlenv/lib/python3.10/site-packages (from torch==2.0.1->torchvision) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in ./rlenv/lib/python3.10/site-packages (from torch==2.0.1->torchvision) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in ./rlenv/lib/python3.10/site-packages (from torch==2.0.1->torchvision) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in ./rlenv/lib/python3.10/site-packages (from torch==2.0.1->torchvision) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in ./rlenv/lib/python3.10/site-packages (from torch==2.0.1->torchvision) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in ./rlenv/lib/python3.10/site-packages (from torch==2.0.1->torchvision) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in ./rlenv/lib/python3.10/site-packages (from torch==2.0.1->torchvision) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in ./rlenv/lib/python3.10/site-packages (from torch==2.0.1->torchvision) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in ./rlenv/lib/python3.10/site-packages (from torch==2.0.1->torchvision) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in ./rlenv/lib/python3.10/site-packages (from torch==2.0.1->torchvision) (2.0.0)\n",
      "Requirement already satisfied: setuptools in ./rlenv/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->torchvision) (65.4.0)\n",
      "Requirement already satisfied: wheel in ./rlenv/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->torchvision) (0.37.1)\n",
      "Requirement already satisfied: cmake in ./rlenv/lib/python3.10/site-packages (from triton==2.0.0->torch==2.0.1->torchvision) (3.26.3)\n",
      "Requirement already satisfied: lit in ./rlenv/lib/python3.10/site-packages (from triton==2.0.0->torch==2.0.1->torchvision) (16.0.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./rlenv/lib/python3.10/site-packages (from requests->torchvision) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./rlenv/lib/python3.10/site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./rlenv/lib/python3.10/site-packages (from requests->torchvision) (2.0.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./rlenv/lib/python3.10/site-packages (from requests->torchvision) (2023.5.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./rlenv/lib/python3.10/site-packages (from jinja2->torch==2.0.1->torchvision) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./rlenv/lib/python3.10/site-packages (from sympy->torch==2.0.1->torchvision) (1.3.0)\n",
      "Requirement already satisfied: numpy in ./rlenv/lib/python3.10/site-packages (1.24.3)\n",
      "Requirement already satisfied: matplotlib in ./rlenv/lib/python3.10/site-packages (3.7.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./rlenv/lib/python3.10/site-packages (from matplotlib) (1.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in ./rlenv/lib/python3.10/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./rlenv/lib/python3.10/site-packages (from matplotlib) (4.39.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in ./rlenv/lib/python3.10/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.20 in ./rlenv/lib/python3.10/site-packages (from matplotlib) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in ./rlenv/lib/python3.10/site-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in ./rlenv/lib/python3.10/site-packages (from matplotlib) (9.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./rlenv/lib/python3.10/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./rlenv/lib/python3.10/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in ./rlenv/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install gymnasium\n",
    "! pip install \"gymnasium[atari, accept-rom-license]\"\n",
    "! pip install torch\n",
    "! pip install torchvision\n",
    "! pip install numpy\n",
    "! pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a753e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘videos’: File exists\n"
     ]
    }
   ],
   "source": [
    "! mkdir logs\n",
    "! mkdir videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "343f5217",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import ale_py\n",
    "#import shimmy\n",
    "import gymnasium as gym\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, random_split, Dataset\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "import random\n",
    "import copy\n",
    "import time\n",
    "import pickle\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a15bb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()   \n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=8, stride=4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=4, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(in_features=64*7*7 , out_features=512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=512, out_features=5)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv_out = self.conv(x)\n",
    "        x = torch.flatten(conv_out, start_dim=1)\n",
    "        return self.fc(x)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c5dce59e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Memory():\n",
    "    \n",
    "    def __init__(self,size):\n",
    "        self.size = size\n",
    "        self.experiences = []\n",
    "    \n",
    "    def sample(self,batch_size):\n",
    "        return random.choices(self.experiences, k=batch_size)\n",
    "        \n",
    "    def add(self, experience):\n",
    "        self.experiences.append(experience)\n",
    "        if len(self.experiences) > self.size:\n",
    "            self.experiences.pop(0)\n",
    "                    \n",
    "    def __len__(self):\n",
    "        return len(self.experiences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f008d8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN_agent:\n",
    "\n",
    "\n",
    "    def __init__(self, lr=0.0001 ,gamma=0.99, epsilon_params=(0.9,0.05,1000)):\n",
    "        # Get cpu, gpu or mps device for training.\n",
    "        self.device = (\n",
    "            \"cuda\"\n",
    "            if torch.cuda.is_available()\n",
    "            else \"mps\"\n",
    "            if torch.backends.mps.is_available()\n",
    "            else \"cpu\"\n",
    "        )\n",
    "        print(f\"Using {self.device} device\")\n",
    "        self.pred_NN = CNN().to(self.device)\n",
    "        self.target_NN = copy.deepcopy(self.pred_NN)\n",
    "        self.target_NN.eval()\n",
    "        self.gamma = gamma\n",
    "        self.epsilon_start = epsilon_params[0]\n",
    "        self.epsilon_end = epsilon_params[1]\n",
    "        self.epsilon_decay = epsilon_params[2]\n",
    "        self.optimizer = torch.optim.RMSprop(self.pred_NN.parameters(), lr=lr)\n",
    "        self.steps_done = 0\n",
    "        \n",
    "    def predict(self, x):\n",
    "        self.steps_done += 1\n",
    "        return self.pred_NN.forward(x)\n",
    "    \n",
    "    def action(self, pred):\n",
    "        eps = self.epsilon_end + (self.epsilon_start - self.epsilon_end) * math.exp(-1. * self.steps_done / self.epsilon_decay)\n",
    "        return (\n",
    "            random.randint(0, pred.size(dim=0) - 1)\n",
    "            if random.random() < eps\n",
    "            else torch.argmax(pred).item()\n",
    "        )\n",
    "    \n",
    "    def train(self, experience_batch):\n",
    "        loss_fn = nn.SmoothL1Loss()\n",
    "        epoch_loss = 0\n",
    "        states = torch.stack([experience_batch[i][0].squeeze(0) for i in range(len(experience_batch))]).to(self.device)\n",
    "        actions = torch.tensor([experience_batch[i][1] for i in range(len(experience_batch))])\n",
    "        rewards = torch.tensor([experience_batch[i][2] for i in range(len(experience_batch))]).to(self.device)#torch.tensor(experience_batch[:][2])\n",
    "        next_states = torch.stack([experience_batch[i][3].squeeze(0)  for i in range(len(experience_batch))]).to(self.device)\n",
    "        terminated = torch.tensor([not experience_batch[i][4] for i in range(len(experience_batch))]).to(self.device)\n",
    "        y = self.estimated_value( rewards, next_states, terminated)\n",
    "        self.optimizer.zero_grad()\n",
    "        pred = self.pred_NN(states)\n",
    "        indicies = torch.LongTensor(actions)\n",
    "        indicies =indicies.unsqueeze(dim=0).T\n",
    "        pred = pred.gather(1,indicies.to(self.device))\n",
    "        loss = loss_fn(y, pred)\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        return epoch_loss\n",
    "        \n",
    "    def copy(self):\n",
    "        self.target_NN.load_state_dict(self.pred_NN.state_dict())  \n",
    "        \n",
    "    def estimated_value(self, reward, next_state, done):\n",
    "        with torch.no_grad():# vectorize it\n",
    "                value_pred = self.target_NN.forward(next_state.to(self.device))\n",
    "                action_pred =  self.pred_NN.forward(next_state.to(self.device))\n",
    "                action_id = torch.argmax(action_pred,1).unsqueeze(1)\n",
    "                value = value_pred.gather(1,action_id)\n",
    "                done = done.unsqueeze(1)\n",
    "                target = reward.unsqueeze(1) + self.gamma * torch.mul(value,done)\n",
    "        return target\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0b4d1cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_to_torch(t):\n",
    "    t = t.unsqueeze(dim=0)\n",
    "    return torch.movedim(t, 3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b7d4bd0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/konrad/Repos/NCML_project/rlenv/lib/python3.10/site-packages/gymnasium/wrappers/record_video.py:87: UserWarning: \u001b[33mWARN: Overwriting existing videos at /home/konrad/Repos/NCML_project/videos folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Episode: 1 Reward: 1.0 loss: 0.0 last rewards: 1.0\n",
      "Episode: 2 Reward: 1.0 loss: 0.0 last rewards: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/konrad/Repos/NCML_project/rlenv/lib/python3.10/site-packages/gymnasium/wrappers/monitoring/video_recorder.py:182: UserWarning: \u001b[33mWARN: Unable to save last video! Did you call close()?\u001b[0m\n",
      "  logger.warn(\"Unable to save last video! Did you call close()?\")\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 60\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(memory) \u001b[39m>\u001b[39m \u001b[39m1000\u001b[39m:\n\u001b[1;32m     59\u001b[0m     experiences_train \u001b[39m=\u001b[39m memory\u001b[39m.\u001b[39msample(batch_size)\n\u001b[0;32m---> 60\u001b[0m     episode_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m agent\u001b[39m.\u001b[39;49mtrain(experiences_train)\n\u001b[1;32m     61\u001b[0m     training_session \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     62\u001b[0m     steps \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "Cell \u001b[0;32mIn[16], line 44\u001b[0m, in \u001b[0;36mDQN_agent.train\u001b[0;34m(self, experience_batch)\u001b[0m\n\u001b[1;32m     42\u001b[0m next_states \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstack([experience_batch[i][\u001b[39m3\u001b[39m]\u001b[39m.\u001b[39msqueeze(\u001b[39m0\u001b[39m)  \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(experience_batch))])\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m     43\u001b[0m terminated \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor([\u001b[39mnot\u001b[39;00m experience_batch[i][\u001b[39m4\u001b[39m] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(experience_batch))])\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m---> 44\u001b[0m y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mestimated_value( rewards, next_states, terminated)\n\u001b[1;32m     45\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     46\u001b[0m pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpred_NN(states)\n",
      "Cell \u001b[0;32mIn[16], line 67\u001b[0m, in \u001b[0;36mDQN_agent.estimated_value\u001b[0;34m(self, reward, next_state, done)\u001b[0m\n\u001b[1;32m     65\u001b[0m         done \u001b[39m=\u001b[39m done\u001b[39m.\u001b[39munsqueeze(\u001b[39m1\u001b[39m)\n\u001b[1;32m     66\u001b[0m         target \u001b[39m=\u001b[39m reward\u001b[39m.\u001b[39munsqueeze(\u001b[39m1\u001b[39m) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgamma \u001b[39m*\u001b[39m torch\u001b[39m.\u001b[39mmul(value,done)\n\u001b[0;32m---> 67\u001b[0m \u001b[39mreturn\u001b[39;00m target\n",
      "Cell \u001b[0;32mIn[16], line 67\u001b[0m, in \u001b[0;36mDQN_agent.estimated_value\u001b[0;34m(self, reward, next_state, done)\u001b[0m\n\u001b[1;32m     65\u001b[0m         done \u001b[39m=\u001b[39m done\u001b[39m.\u001b[39munsqueeze(\u001b[39m1\u001b[39m)\n\u001b[1;32m     66\u001b[0m         target \u001b[39m=\u001b[39m reward\u001b[39m.\u001b[39munsqueeze(\u001b[39m1\u001b[39m) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgamma \u001b[39m*\u001b[39m torch\u001b[39m.\u001b[39mmul(value,done)\n\u001b[0;32m---> 67\u001b[0m \u001b[39mreturn\u001b[39;00m target\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1457\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:701\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1152\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1135\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:312\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Repos/NCML_project/rlenv/lib/python3.10/site-packages/debugpy/_vendored/pydevd/pydevd.py:2070\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[1;32m   2067\u001b[0m             from_this_thread\u001b[39m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[1;32m   2069\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_threads_suspended_single_notification\u001b[39m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[0;32m-> 2070\u001b[0m         keep_suspended \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_wait_suspend(thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\n\u001b[1;32m   2072\u001b[0m frames_list \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   2074\u001b[0m \u001b[39mif\u001b[39;00m keep_suspended:\n\u001b[1;32m   2075\u001b[0m     \u001b[39m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[0;32m~/Repos/NCML_project/rlenv/lib/python3.10/site-packages/debugpy/_vendored/pydevd/pydevd.py:2106\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[1;32m   2103\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_input_hook()\n\u001b[1;32m   2105\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess_internal_commands()\n\u001b[0;32m-> 2106\u001b[0m     time\u001b[39m.\u001b[39;49msleep(\u001b[39m0.01\u001b[39;49m)\n\u001b[1;32m   2108\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[39mstr\u001b[39m(\u001b[39mid\u001b[39m(frame)))\n\u001b[1;32m   2110\u001b[0m \u001b[39m# process any stepping instructions\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#initialize environment\n",
    "env = gym.make(\"ALE/Pacman-v5\", render_mode=\"rgb_array\")\n",
    "env.seed(543)\n",
    "env = gym.wrappers.AtariPreprocessing(env, screen_size=84, grayscale_obs=False, frame_skip=1, noop_max=30)\n",
    "env = gym.wrappers.RecordVideo(env, './videos', episode_trigger = lambda x: (x+1) % 100 == 0)# PATH\n",
    "# env = NoopResetEnv(env, noop_max=30)\n",
    "replay_buffer = Memory(5000)\n",
    "torch.manual_seed(53407)\n",
    "actions = range(env.action_space.n)\n",
    "device = (\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "#hyperparams\n",
    "max_steps = 9999\n",
    "training_freq = 1\n",
    "copying_freq = 10\n",
    "batch_size = 64\n",
    "\n",
    "#initialize agent\n",
    "agent = DQN_agent(lr=2e-4,gamma=0.99)\n",
    "\n",
    "training_session = 0\n",
    "max_episode = 5000\n",
    "\n",
    "#loops until max_time is reached\n",
    "memory = Memory(10000)\n",
    "\n",
    "total_steps = 0\n",
    "last_rewards = []\n",
    "\n",
    "episodes = []\n",
    "losses = []\n",
    "logger = {\"episodes\":[],\"losses\":[]}\n",
    "for episode  in range(1,max_episode):\n",
    "    #get first states\n",
    "    state = env.reset()\n",
    "    state = state[0]/255\n",
    "    state = torch.Tensor(state)\n",
    "    state = adjust_to_torch(state)\n",
    "    #loops until experience_capacity is reached\n",
    "    episode_reward = 0 \n",
    "    episode_loss = 0\n",
    "    steps = 0\n",
    "    for i in range(1, max_steps):\n",
    "        #predict q-values and choose action\n",
    "        with torch.no_grad():\n",
    "            pred = agent.predict(state.to(device))\n",
    "        action = agent.action(pred)\n",
    "        #get next states\n",
    "        next_state, reward, terminated, truncated, info = env.step(action)\n",
    "        episode_reward += reward\n",
    "        if i == max_steps - 1:\n",
    "            print(\"Max steps reached.\")\n",
    "        next_state = adjust_to_torch(torch.tensor(next_state)/255)\n",
    "        experience = [state, action, reward, next_state, terminated] \n",
    "        memory.add(experience)\n",
    "        if terminated or truncated:\n",
    "            break\n",
    "        state = next_state      \n",
    "        if len(memory) > 1000:\n",
    "            experiences_train = memory.sample(batch_size)\n",
    "            episode_loss += agent.train(experiences_train)\n",
    "            training_session += 1\n",
    "            steps += 1\n",
    "        total_steps += 1\n",
    "        steps = i\n",
    "    #if episode % 100 == 0:\n",
    "    if episode % copying_freq == 0:\n",
    "        agent.copy()\n",
    "    if episode % 2 == 0:\n",
    "        logger[\"episodes\"].append(episodes)\n",
    "        logger[\"losses\"].append(losses)\n",
    "        episodes = []\n",
    "        losses = []\n",
    "    if episode % 500 == 0:\n",
    "        with open('./logs/logger_ddqn.json', 'w') as fp:# PATH\n",
    "            json.dump(logger, fp)\n",
    "    last_rewards.append(episode_reward)\n",
    "    episodes.append(episode_reward)\n",
    "    losses.append(episode_loss/steps)\n",
    "    if steps > 0:\n",
    "      print(f\"Episode: {episode} Reward: {episode_reward} loss: {episode_loss/steps} last rewards: {sum(last_rewards)/len(last_rewards)}\")\n",
    "    if episode % 1000 == 0:  \n",
    "        torch.save(agent.pred_NN.state_dict(), \"./pred.pt\")\n",
    "        torch.save(agent.target_NN.state_dict(), \"./target.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7746d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
